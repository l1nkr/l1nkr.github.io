<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.0" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="今天git使用遇到了一个问题 问题背景公司存在一个仓库，还有自己fork的仓库，以及本地仓库。公司仓库的master分支一只在进行开发，fork的仓库和我本地的保持一致，本地仓库是基于之前公司仓库的一个分支进行开发的 上游仓库存在一个分支a，远程仓库以及本地仓库都存在一个a分支但是后来上游仓库将分支a删除了，我之前向上游提交的pr也都被revert了 在这种情况，我希望能够将我新开发的特性融入到上">
<meta property="og:type" content="article">
<meta property="og:title" content="git">
<meta property="og:url" content="http://example.com/2021/07/12/git/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="今天git使用遇到了一个问题 问题背景公司存在一个仓库，还有自己fork的仓库，以及本地仓库。公司仓库的master分支一只在进行开发，fork的仓库和我本地的保持一致，本地仓库是基于之前公司仓库的一个分支进行开发的 上游仓库存在一个分支a，远程仓库以及本地仓库都存在一个a分支但是后来上游仓库将分支a删除了，我之前向上游提交的pr也都被revert了 在这种情况，我希望能够将我新开发的特性融入到上">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-07-12T10:33:06.000Z">
<meta property="article:modified_time" content="2021-07-12T11:06:32.555Z">
<meta property="article:author" content="Nick">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Pisces',
    version: '6.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://example.com/2021/07/12/git/"/>





  <title>Hexo</title>
  








<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/15/logic-prolem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/15/logic-prolem/" itemprop="url">逻辑问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-07-15T22:31:41+08:00">2021-07-15</time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>今天晚上看到了几个比较有意思的问题，在这里记录一下<br>以下“xx问题 ”都是自创词汇</p>
<h3 id="验毒问题"><a href="#验毒问题" class="headerlink" title="验毒问题"></a>验毒问题</h3><blockquote>
<p><strong>题目：1000瓶酒，其中有一瓶有毒，老鼠喝了毒酒会在一天之后死亡。给你一天时间，要用最少的老鼠数量找出毒酒</strong></p>
</blockquote>
<ol>
<li>拿出十个碗</li>
<li>对每瓶酒使用二进制进行编号</li>
<li>遍历一千瓶酒。取出每瓶酒二进制位为 1 的下标，滴入对应下标的碗中</li>
<li>十只老鼠分别喝一个碗里面的酒，一天之后死了的老鼠的下标标志位为1。</li>
<li>此标志位恢复为十进制就是毒酒的编号</li>
</ol>
<h3 id="天平问题"><a href="#天平问题" class="headerlink" title="天平问题"></a>天平问题</h3><blockquote>
<p><strong>问题：八个小球，其中有一个重量较轻的，使用天平找出较轻小球。要求尽可能少使用天平</strong><br>这个问题首先想到的就是二分法，每次排除一半，需要秤三次。<br>但是还有更优的解法，只需要秤两次就可以求解出来。</p>
</blockquote>
<ol>
<li>任意拿出六个球，称一次</li>
<li><ol>
<li>如果步骤一重量相同，秤剩下的两个小球，得出结果</li>
<li>如果步骤一重量不相同，在较轻的那三个里面任意拿两个出来秤。<ol>
<li>如果重量相同，剩下那一个就是结果</li>
<li>如果重量不相同，较轻的那个就是结果</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="帽子问题"><a href="#帽子问题" class="headerlink" title="帽子问题"></a>帽子问题</h3><blockquote>
<p><strong>问题：晚会上参会人做了一个游戏。每人随机分了一顶白色或黑色的帽子（黑帽子至少有1顶）。每人都可以看到其它人的帽子颜色，但不能看到自己的。主持人说让大家根据别人帽子的颜色猜黑色帽子的个数，规则如下：关灯，如果有人知道了黑色帽子的个数马上报出来；如果没人报，打开灯，让大家观察，然后回到第1步。第一次关灯，没人报数；开灯然后第二次关灯，仍没有动静；直到第三次开灯关灯后，才有人报数。请问，有几顶黑帽子？</strong></p>
</blockquote>
<ol>
<li>假设只有一个黑帽子。黑帽A在一开始就会发现周围全部都是白帽，而又最少有一个黑帽，所以他会判断就是自己，所以第一次关灯就会报数</li>
<li>假设有两个黑帽。<ol>
<li>黑帽A B，在第一次时发现周围有一个黑帽，但是他不确定自己是不是黑帽，所以第一次他们都不会报数</li>
<li>黑帽A B，在基于第一次没人报数以及看到一顶黑帽的情况下，可以判断有两个黑帽，而自己只看到了一个黑帽，所以可以判断自己就是黑帽，所以第二次关灯会报数</li>
</ol>
</li>
<li>假设有三个黑帽<ol>
<li>黑帽A B C，在第一次时发现周围有两个黑帽，但是他不确定自己是不是黑帽，所以第一次他们都不会报数</li>
<li>黑帽A B C，在第二次时发现周围有两个黑帽，但是他仍然不确定自己是不是黑帽，所以第二次依然不会报数</li>
<li>黑帽A B C，在第三次时发现周围有两个黑帽，同时他们知道如果只有两个黑帽的话，那么第二次关灯就会报数。但是没有人报数，所以会判断有三个黑帽，从而确定自己就是黑帽，然后就会报数</li>
</ol>
</li>
</ol>
<p>之后的话依次类推，第几次关灯报数就有几个黑帽</p>
<h3 id="药片问题"><a href="#药片问题" class="headerlink" title="药片问题"></a>药片问题</h3><blockquote>
<p><strong>一个人需要吃两种药，每种药有两片，早晚每种药应该各吃一片，但是四个药片混合在一起了,应该使用什么策略吃药</strong><br>磨碎了吃…</p>
</blockquote>
<h3 id="分水问题"><a href="#分水问题" class="headerlink" title="分水问题"></a>分水问题</h3><blockquote>
<p><strong>只有 5L 和 6L 的瓶子，如何得到 3L 的水</strong></p>
</blockquote>
<ol>
<li>把 5l 的倒满.</li>
<li>把 5l 水倒入 6l 的。</li>
<li>再倒一杯 5l，倒 1l 给 6l，剩下 4l。</li>
<li>把 6l 倒掉，把 4l 倒入。</li>
<li>把 5l 的杯子装满，倒 2l 给 6l 的。3l 就有了。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/12/git/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/12/git/" itemprop="url">git</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-07-12T18:33:06+08:00">2021-07-12</time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>今天git使用遇到了一个问题</p>
<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>公司存在一个仓库，还有自己fork的仓库，以及本地仓库。<br>公司仓库的master分支一只在进行开发，fork的仓库和我本地的保持一致，本地仓库是基于之前公司仓库的一个分支进行开发的</p>
<p>上游仓库存在一个分支a，远程仓库以及本地仓库都存在一个a分支<br>但是后来上游仓库将分支a删除了，我之前向上游提交的pr也都被revert了</p>
<p>在这种情况，我希望能够将我新开发的特性融入到上游最新的分支应该如何做呢?</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>我的思路是这样的，首先在本地建立一个分支，然后将上游最新分支拉到这个分支，<br>然后将我含有我新特性的分支merge到新拉下来的分支，然后进行pr</p>
<p>存在的问题是</p>
<ol>
<li>存在冲突 这个比较好解决，手动解决一下冲突就可以</li>
<li>以前提交的代码被revert 不知道如何进行解决，如何被revert了，那么我的新特性就无法实现了</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/12/osnote-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/12/osnote-md/" itemprop="url">操作系统知识点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-07-12T10:38:16+08:00">2021-07-12</time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="第一章-导论"><a href="#第一章-导论" class="headerlink" title="第一章 导论"></a>第一章 导论</h2><p>现代通用计算机系统由一个或多个CPU和若干设备控制器通过共同的总线相连而成。</p>
<p>打开电源或重启——运行初始化程序（引导程序）——定位操作系统并将其装入内存——执行第一个进程</p>
<p>引导程序：通常位于ROM或者EEPROM，称为计算机硬件中的固件。用来初始化系统的所有部分（CPU寄存器，设备控制器和内存）。<br>中断：硬件可随时通过系统总线向CPU发出信号，出发中断。软件通过系统调用（或者其他特别操作）触发中断。<br>发生中断——调用一个通用子程序检查中断信息——使用中断处理指针表（中断向量）——间接调用中断处理子程序</p>
<p>现在的操作系统都是以中断为驱动的。</p>
<p>操作系统三种基本类型</p>
<ul>
<li>Batch systems（批处理系统）</li>
<li>Time-sharingsystems（分时系统）</li>
<li>Real timesystems（实时系统）</li>
</ul>
<h2 id="第二章-操作系统结构"><a href="#第二章-操作系统结构" class="headerlink" title="第二章 操作系统结构"></a>第二章 操作系统结构</h2><h3 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h3><p>向操作系统传递参数的三种方法</p>
<ol>
<li>通过寄存器来传递参数。</li>
<li>若参数数量比寄存器多，参数通常存在内存的块和表中，并将块的地址通过寄存器来传递。</li>
<li>参数也可以通过程序放在或压入堆栈中，并通过操作系统弹出。<h4 id="系统调用类型"><a href="#系统调用类型" class="headerlink" title="系统调用类型"></a>系统调用类型</h4>进程控制、文件管理、设备管理、信息维护和通信</li>
</ol>
<h4 id="系统程序分类"><a href="#系统程序分类" class="headerlink" title="系统程序分类"></a>系统程序分类</h4><p>文件管理、状态信息、文件修改、程序语言支持、程序装入和执行、通信。</p>
<h3 id="操作系统结构"><a href="#操作系统结构" class="headerlink" title="操作系统结构"></a>操作系统结构</h3><p>简单结构、分层方法、微内核、模块、虚拟机</p>
<h4 id="分层方法"><a href="#分层方法" class="headerlink" title="分层方法"></a>分层方法</h4><p>定义：操作系统分成若干层（级）。最底层（层0）为硬件，最高层（层N）为用户接口。每层只考虑较低层的功能和服务。</p>
<p>优点：</p>
<ul>
<li>每层都是利用较低层所提供的功能实现的，并为叫高层隐藏了一定的数据结构、操作和硬件的存在<br>缺点：</li>
<li>分层法的主要困难涉及对层的详细定义<br>与其它方法相比效率较差</li>
</ul>
<h4 id="微内核"><a href="#微内核" class="headerlink" title="微内核"></a>微内核</h4><p>微内核方法将所有非基本部分从内核中移走，并将它们实现为系统或用户程序，这样得到了更小的内核。<br>微内核的主要功能是使客户程序和运行在用户空间的各种服务之间进行通信。</p>
<p>优点：</p>
<ul>
<li>便于扩充操作系统</li>
<li>很容易从一种硬件平台设计移植到另一种硬件平台设计</li>
<li>更安全、可靠</li>
</ul>
<p>缺点：</p>
<ul>
<li>由于系统功能总开销的增加而导致系统性能的下降。</li>
</ul>
<h4 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h4><p>大多数现代操作系统实现内核模块：</p>
<p>采用面向对象的方法</p>
<p>每个核心组件是分开的</p>
<p>每部分与已知接口的其他部分通信</p>
<p>每部分根据需要加载到内核</p>
<p>总之，类似于层，但更灵活。</p>
<h2 id="第三章-进程"><a href="#第三章-进程" class="headerlink" title="第三章 进程"></a>第三章 进程</h2><h3 id="进程概念"><a href="#进程概念" class="headerlink" title="进程概念"></a>进程概念</h3><h4 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h4><p>进程包含了程序代码和当前活动（其中当前活动通过程序计数器和处理器寄存器的内容表示）两个部分，进程是执行中的程序。具体有：</p>
<ul>
<li>文本段（代码段）</li>
<li>数据段（全局变量）</li>
<li>栈（stack）（包含临时数据、函数参数、返回地址、局部变量）</li>
<li>堆（heap）（进程运行期间动态分配的内存）</li>
<li>程序计数器<br>注意： 程序是被动实体，进程是活动实体（其中当前活动通过程序计数器和处理器寄存器的内容表示）</li>
</ul>
<p>两个进程可以与同一程序联系，虽然文本段相同。但是数据段、堆栈段不同</p>
<h4 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h4><ul>
<li>New（新的）</li>
<li>Running（运行）</li>
<li>Waiting（等待）</li>
<li>Ready（就绪）</li>
<li>Terminated（终止）</li>
</ul>
<h4 id="进程控制块（PCB）"><a href="#进程控制块（PCB）" class="headerlink" title="进程控制块（PCB）"></a>进程控制块（PCB）</h4><p>每一个进程都需要分配一定的信息，这些信息的仓库就叫做PCB，PCB有以下功能：</p>
<p>系统利用PCB 控制 和 管理 进程<br>PCB是进程存在的唯一标志<br>操作系统通过PCB感知进程的存在</p>
<ul>
<li>程序计数器：表示进程要执行的下个指令的地址</li>
<li>CPU寄存器：与程序计数器一起，在出现中断时状态信息需要保存，使进程能够正确执行</li>
<li>CPU调度信息：包括优先级、调度队列的指针等（见第五章）</li>
<li>内存管理信息：（见第八章）</li>
<li>记账信息：包括CPU时间、实际使用时间、时间界限、记账数据、作业和进程数量等</li>
<li>IO状态信息：分配给进程的IO设备列表，打开的文件列表等</li>
</ul>
<h3 id="进程调度"><a href="#进程调度" class="headerlink" title="进程调度"></a>进程调度</h3><h4 id="调度队列"><a href="#调度队列" class="headerlink" title="调度队列"></a>调度队列</h4><ul>
<li>作业（Job）队列：包含了系统中所有的进程</li>
<li>就绪（Ready）队列：包含了系统中，驻留在内存中就绪的，准备运行的进程<br>  该队列通常用链表实现，头结点指向第一个和最后一个PCB块的指针，每个PCB块包括指向下一个PCB的指针域</li>
<li>设备（Device）队列：包含了等待特定IO设备的进程列表<br>  进程可能会有IO请求，请求时可能IO设备在处理其他请求，所以该进程需要等待。</li>
</ul>
<h4 id="调度程序"><a href="#调度程序" class="headerlink" title="调度程序"></a>调度程序</h4><p>长期调度程序（long-term schedule） / 作业调度程序（job schedule）：负责从缓冲池中选择进程，装入内存以便执行<br>短期调度程序（short-term schedule） / CPU调度程序（CPU schedule）：从执行的进程中选择进程，并为之分配CPU</p>
<h3 id="进程调度-1"><a href="#进程调度-1" class="headerlink" title="进程调度"></a>进程调度</h3><h4 id="进程创建"><a href="#进程创建" class="headerlink" title="进程创建"></a>进程创建</h4><p>进程是需要一定的资源的（CPU时间，内存，文件，IO设备），在一个进程创建子进程的时候，在父进程和子进程之间需要分配 / 共享资源，有以下几种情况：</p>
<ul>
<li>从操作系统哪里获取资源</li>
<li>从父进程中获取资源（限制子进程只能从父进程中获取资源能防止创建过多的进程导致系统超载）</li>
</ul>
<p>在进程创建时，该进程会得到：</p>
<ul>
<li>各种物理和逻辑资源</li>
<li>父进程传递来的初始化数据或输入</li>
<li>通常子进程会返回给父进程自身的标识符（系统中唯一标识进程身份的id）</li>
</ul>
<h4 id="进程终止"><a href="#进程终止" class="headerlink" title="进程终止"></a>进程终止</h4><p>进程终止的时间：</p>
<ul>
<li>执行完最后语句，并使用系统调用exit()请求操作系统删除自身。</li>
<li>一个进程通过适当的系统调用终止另一个进程（通常这个进程需要是被终止进程的父进程，并且这需要知道被终止进程的标识符）</li>
</ul>
<p>父进程终止子进程的原因一般有：</p>
<ul>
<li>子进程使用的资源超过了父进程分配的资源</li>
<li>分配给子进程的任务不再需要</li>
<li>父进程退出，在这种情况下，操作系统不允许子进程继续.有些系统如果一个进程终止，那么它所有的子进程都终止。这叫做级联终止。通常有操作系统进行</li>
</ul>
<p>进程终止后：</p>
<ul>
<li>进程会返回状态值（通常为整数）到父进程</li>
<li>所有进程资源会被操作系统释放</li>
</ul>
<p>如果父进程终止，那么其所有子进程会以init进程作为父进程。因此，子进程仍然有一个父进程来收集状态和执行统计</p>
<h3 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h3><p>并发执行的进程有两类，<strong>一类是 独立进程，不能影响其他进程并且不被其他进程影响。</strong><br><strong>另一类是协作进程，能影响其他进程或被其他进程影响</strong></p>
<p>允许进程协作的优点：</p>
<ul>
<li>信息共享</li>
<li>提高运算速度</li>
<li>模块化</li>
<li>方便</li>
</ul>
<p>因此协作进程需要一种进程间通信机制（IPC）来允许进程相互交换数据与信息。有<strong>共享内存和信息传递</strong>两种类型</p>
<p>共享内存系统</p>
<ul>
<li>比消息传递更快</li>
<li>只在建立共享内存区时需要系统调用</li>
</ul>
<p>消息传递：</p>
<ul>
<li>不需要避免冲突</li>
<li>通常需要系统调用实现，需要更多的内核介入的时间消耗</li>
</ul>
<h2 id="第四章-线程"><a href="#第四章-线程" class="headerlink" title="第四章 线程"></a>第四章 线程</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>线程是CPU使用的基本单元，由<strong>线程ID，程序计数器，寄存器集合和栈</strong>组成。<br>它与属于同一进程的其他线程共享<strong>代码段，数据段和其他操作系统资源</strong></p>
<h4 id="多线程优点"><a href="#多线程优点" class="headerlink" title="多线程优点"></a>多线程优点</h4><ul>
<li>响应度高：一个多线程的程序即使部分阻塞，其他部分仍能运行，从而增加了对用户的响应程度。</li>
<li>资源共享</li>
<li>经济：创建和切换线程比创建进程更节省资源和时间</li>
<li>多处理器体系结构的利用</li>
</ul>
<h4 id="多线程模型"><a href="#多线程模型" class="headerlink" title="多线程模型"></a>多线程模型</h4><p>多对一<br>一对一<br>多对多</p>
<h3 id="多线程问题"><a href="#多线程问题" class="headerlink" title="多线程问题"></a>多线程问题</h3><h4 id="fork-exec"><a href="#fork-exec" class="headerlink" title="fork() exec()"></a>fork() exec()</h4><p>在多线程程序中，系统调用fork()和exec()的语义有所改变。</p>
<p>如果程序中一个进程调用fork()，那么新进程会复制所有线程，还是新进程只有单个线程？<br><strong>有的UNIX系统有两种形式的fork()，一种复制所有线程，另一种只复制调用了系统调用fork()的线程。</strong></p>
<p>Exec()工作方式：<strong>如果一个线程调用系统调用exec()，那么exec()参数所指定的程序会替换整个进程，包括所有线程。</strong></p>
<p>如果调用fork()之后立即调用exec()，那么没有必要复制所有线程，因为exec()参数所指定的程序会替换整个进程。在这种情况下，只复制调用线程比较适当。<br>不过，如果在fork()之后另一进程并不调用exec(),那么另一进程就应复制所有进程。</p>
<h3 id="线程取消"><a href="#线程取消" class="headerlink" title="线程取消"></a>线程取消</h3><p><strong>线程取消（Thread cancellation）是在线程完成之前来终止线程。</strong><br>被取消的线程通常被称为目标线程（target thread）。<br>取消一个目标线程可能发生在两个不同的场景:</p>
<ul>
<li>异步取消（Asynchronous cancellation）：一个线程立即终止目标线程。</li>
<li>延迟取消（Deferred cancellation）：目标线程定期检查自己是否应该终止，这允许目标线程有机会以有序方式来终止自己。</li>
</ul>
<p>当资源被分配给一个被取消的线程，或者要取消的线程正在更新与其他线程共享的数据时，那么线程取消就会遇到麻烦。尤其对于异步取消非常麻烦。</p>
<p>通常，操作系统会从被取消的线程中回收系统资源，但不会回收所有资源。<br>因此，异步取消线程可能无法释放必要的系统资源。</p>
<p>对于延迟取消，则相反，一个线程指示目标线程被取消，但是只有在目标线程检查了一个标志以确定是否应该取消它之后才会发生取消。<br>线程可以在一个可以被安全取消的点上执行此检查。<br>在Pthreads中，线程取消使用pthread_cancel()函数。目标线程的标识符作为参数传递给该函数。<br>调用pthread_cancel()只表示要取消目标线程的请求。然而，真实的取消取决于目标线程是如何设置来处理这个请求的<br>Pthreads允许<strong>关闭（disabled）或者开启（enabled）线程取消</strong>。</p>
<p>显然，如果关闭（disabled）了线程取消，则不能取消线程。但是，取消请求仍在等待中，因此线程可以稍后启用（enabled）线程取消并响应请求。<br>默认的线程取消类型是延迟取消（deferred cancellation）。在延迟取消模式下，只有当线程到达了取消点（cancellation point）,线程取消才会发生。<br>建立取消点的一种技术是调用pthread_testcancel()函数。如果发现取消请求正在等待，将调用一个名为清除处理程序（cleanup handler）的函数。该函数允许在线程终止之前，释放掉线程可能获得的任何资源。</p>
<h3 id="并发与并行"><a href="#并发与并行" class="headerlink" title="并发与并行"></a>并发与并行</h3><p>从CUP资源占用角度考虑并发与并行：</p>
<p>并发：单个CPU的操作系统在进行多线程操作时，将CPU运行时间划分成若干个时间段，再将时间段分配给各个线程执行，在一个时间段内只运行一个线程，其他线程处于挂起状态。</p>
<p>并行：对于多CPU系统进行多线程操作，一个CPU在执行一个线程时，另一个CPU执行另一个线程。两个线程互不抢CPU资源，可以同时进行。<br><img src="/2021/07/12/osnote-md/Xnip2021-06-03_14-25-46.jpg"></p>
<h3 id="共享"><a href="#共享" class="headerlink" title="共享"></a>共享</h3><p><strong>互斥共享方式</strong></p>
<p><strong>同时访问方式</strong><br>“同时”通常是宏观上的，微观上可能是进行交替对该资源进行访问</p>
<h4 id="硬中断-软中断"><a href="#硬中断-软中断" class="headerlink" title="硬中断 软中断"></a>硬中断 软中断</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/aresxin/articles/9152136.html">https://www.cnblogs.com/aresxin/articles/9152136.html</a><br>举一个简单的例子<br>程序（io请求）&lt;—–&gt; 内核 (io请求) &lt;—–&gt; 硬件设备<br>             软中断                硬中断</p>
<h4 id="孤儿进程-僵尸进程"><a href="#孤儿进程-僵尸进程" class="headerlink" title="孤儿进程 僵尸进程"></a>孤儿进程 僵尸进程</h4><p>僵尸进程：父进程仍运行 &amp;&amp; 子进程已结束 &amp;&amp; 父进程未对子进程调用wait()<br>孤儿进程：孤儿进程可能是由于级联终止造成的吧，比如说父进程突然终止了，那么进程树下的子进程也应该被终止，在子进程未被终止前它是一个孤儿进程，孤儿进程是一个很短暂的状态，因为他一旦成为了孤儿进程就会有人来收养他，比如说init进程</p>
<h4 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h4><p>单线程程序的信号处理比较直接，信号总是发送给进程。<br>当多线程时，信号会</p>
<ul>
<li>发送信号到信号所应用的线程</li>
<li>发送信号到进程内的每个线程</li>
<li>发送信号到进程内的某些固定线程</li>
<li>规定一个特定线程以接收进程的所有信号。</li>
</ul>
<p>发送信号的方法依赖于信号的类型。</p>
<h4 id="TLS-线程局部存储-thread-local-storage"><a href="#TLS-线程局部存储-thread-local-storage" class="headerlink" title="TLS 线程局部存储 thread local storage"></a>TLS 线程局部存储 thread local storage</h4><p>同属一个进程的线程共享进程数据<br>在某些情况下每个线程可能需要一定数据的自己的副本，这种数据称为线程特定数据。可以让每个线程与其唯一的标识符相关联</p>
<h2 id="第五章-CPU调度"><a href="#第五章-CPU调度" class="headerlink" title="第五章 CPU调度"></a>第五章 CPU调度</h2><h4 id="抢占调度"><a href="#抢占调度" class="headerlink" title="抢占调度"></a>抢占调度</h4><p>CPU调度决策可在如下4种情况环境下发生：</p>
<ul>
<li>当一个进程从运行切换到等待状态（如：I/O请求，或者调用wait等待一个子进程的终止）</li>
<li>当一个进程从运行状态切换到就绪状态（如：出现中断）</li>
<li>当一个进程从等待状态切换到就绪状态（如：I/O完成）</li>
<li>当一个进程终止时<br>抢占调度对访问共享数据是有代价（如加锁）的，有可能产生错误，需要新的机制（如，同步）来协调对共享数据的访问。<br>抢占对于操作系统内核的设计也有影响。在处理系统调用时，内核可能忙于进程活动。这些活动可能涉及要改变重要内核数据(如I/O队列)。</li>
</ul>
<h4 id="分派程序"><a href="#分派程序" class="headerlink" title="分派程序"></a>分派程序</h4><p>分派程序（dispatch）是一个模块，用来将CPU的控制交给由短期调度程序选择的进程。<br>其功能包括：</p>
<ul>
<li>切换上下文</li>
<li>切换到用户模式</li>
<li>跳转到用户程序的合适位置，以重新启动程序。<br>分派程序停止一个进程而启动另一个所花的时间成为分派延迟。</li>
</ul>
<h3 id="调度准则"><a href="#调度准则" class="headerlink" title="调度准则"></a>调度准则</h3><ul>
<li>CPU使用率 : 需要使CPU尽可能忙</li>
<li>吞吐量 : 指一个时间单元内所完成进程的数量</li>
<li>周转时间 :从进程提交到进程完成的时间段称为周转时间，周转时间是所有时间段之和，包括等待进入内存、在就绪队列中等待、在CPU上执行和I/O执行</li>
<li>等待时间 : 在就绪队列中等待所花费时间之和</li>
<li>响应时间 : 从提交请求到产生第一响应的时间</li>
</ul>
<h3 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h3><ul>
<li>先来先服务(FCFS)</li>
<li>最短作业优先(SJF)</li>
<li>最短剩余时间优先调度</li>
<li>优先级调度</li>
<li>轮转法调度</li>
<li>多级队列调度</li>
<li>多级反馈地队列调度</li>
</ul>
<p>Linux 从整体上区分实时进程和普通进程，因为实时进程和普通进程度调度是不同的，它们两者之间，实时进程应该先于普通进程而运行，然后，对于同一类型的不同进程，采用不同的标准来选择进程。对普通进程的调度策略是动态优先调度，对于实时进程采用了两种调度策略，FIFO(先来先服务调度)和RR（时间片轮转调度）。</p>
<p>UNIX系统是单纯的分时系统，所以没有设置作业调度。UNIX系统的进程调度采用的算法是，多级反馈队列调度法。其核心思想是先从最高休先级就绪队列中取出排在队列最前面的进程，当进程执行完一个时间片仍未完成则剥夺它的执行，将它放入到相应的队列中，取出下一个就绪进程投入运行，对于同一个队列中的各个进程，按照时间片轮转法调度。多级反馈队列调度算法即能使高优先级的作业得到响应又能使短作业（进程）迅速完成。但是它还是存在某些方面的不足，当不断有新进程到来时，则长进程可能饥饿。</p>
<p>Windows 系统其调度方式比较复杂，它的处理器调度的调度单位是线程而不是进程，是基于优先级的抢占式多处理器调度，依据优先级和分配时间片来调度。而且Windows 2000/XP在单处理器系统和多处理器系统中的线程调度是不同的线程调度机制，Windows操作系统的调度系统总是运行优先级最高的就绪线程。在同一优先级的各线程按时间片轮转算法进行调度。如果一个高优先级的线程进入就绪状态，当前运行的线程可能在用完它的时间片之前就被抢占处理机。</p>
<h2 id="第六章-进程同步"><a href="#第六章-进程同步" class="headerlink" title="第六章 进程同步"></a>第六章 进程同步</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>多个进程并发访问和操作同一数据且执行结果与访问发生的特定顺序有关，称之为竞争条件（race condition）</p>
<h3 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h3><p>临界区问题满足三项要求</p>
<ul>
<li>互斥</li>
<li>前进</li>
<li>有限等待</li>
</ul>
<p>一个操作系统，在某个时刻，可同时存在有多个处于内核模式的活动进程，因此实现操作系统的内核代码，会存在竞争条件。内核开发人员有必要确保其操作系统不会产生竞争条件。<br>有两种方法用于处理操作系统内的临界区问题：</p>
<p><strong>抢占内核（preemptive kernel）与非抢占内核（nonpreemptive kernel）：</strong><br>抢占内核允许处于内核模式的进程被抢占。<br>非抢占内核不允许内核模式的进程被抢占。</p>
<h3 id="peterson-算法"><a href="#peterson-算法" class="headerlink" title="peterson 算法"></a>peterson 算法</h3><h3 id="硬件同步"><a href="#硬件同步" class="headerlink" title="硬件同步"></a>硬件同步</h3><h3 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h3><h4 id="系统表"><a href="#系统表" class="headerlink" title="系统表"></a>系统表</h4><p>资源的申请与释放为系统调用。其他资源的申请与释放可以通过信号量的wait与signal操作或通过互斥锁的获取与释放来完成。因此对于进程和线程的每次使用，操作系统会检查以确保使用进程已经申请并获得了资源。</p>
<p>系统表记录了每个资源是否空闲或已被分配，分配给了哪个进程。如果进程正在申请的资源正在为其他进程所使用，那么该进程会增加到该资源的等待队列。</p>
<h3 id="经典同步问题"><a href="#经典同步问题" class="headerlink" title="经典同步问题"></a>经典同步问题</h3><ul>
<li>有限缓存-生产者消费问题</li>
<li>读者-写者问题</li>
<li>哲学家进餐</li>
</ul>
<h2 id="第七章-死锁"><a href="#第七章-死锁" class="headerlink" title="第七章 死锁"></a>第七章 死锁</h2><h3 id="死锁特征"><a href="#死锁特征" class="headerlink" title="死锁特征"></a>死锁特征</h3><h4 id="必要条件"><a href="#必要条件" class="headerlink" title="必要条件"></a>必要条件</h4><ul>
<li>互斥</li>
<li>占有并等待</li>
<li>非抢占</li>
<li>循环等待</li>
</ul>
<h3 id="死锁处理方法"><a href="#死锁处理方法" class="headerlink" title="死锁处理方法"></a>死锁处理方法</h3><ul>
<li>可使用协议以预防或避免死锁，确保系统不会进入死锁状态。</li>
<li>可允许系统进入死锁状态，然后检测它，并加以修复。</li>
<li>可忽略这个问题，认为死锁不可能在系统内发生。</li>
<li>*死锁预防（deadlock prevention）**是一组方法，以确保至少一个必要条件不成立。这些方法通过限制如何申请资源的方法来预防死锁。</li>
</ul>
<p><strong>死锁避免（deadlock avoidance）</strong>要求操作系统事先得到有关进程申请资源和使用资源的额外信息。有了这些额外信息，系统可以确定：对于一个申请，进程是否应等待。为了确定当前申请是允许还是延迟，系统必须考虑可用资源，已经分配给每个进程的资源，每个进程将来申请和释放的资源。</p>
<h3 id="死锁预防"><a href="#死锁预防" class="headerlink" title="死锁预防"></a>死锁预防</h3><blockquote>
<p>出现死锁有四个必要条件，只要保证至少一个条件不成立，就能预防死锁的发生。</p>
</blockquote>
<h4 id="互斥"><a href="#互斥" class="headerlink" title="互斥"></a>互斥</h4><p>对于非共享资源，必须要有互斥条件（如打印机）。另一方面，共享资源不要求互斥访问，因此不会涉及死锁（如只读文件）。<br>故通常不能通过否定互斥条件来预防死锁，有的资源本身就是非共享的。</p>
<h4 id="占有并等待"><a href="#占有并等待" class="headerlink" title="占有并等待"></a>占有并等待</h4><p>为了确保占有并等待条件不会在系统内出现，必须保证：当一个进程申请一个资源时，就不能占有其他资源。</p>
<ul>
<li>方法一：可以通过要求申请资源的系统调用在所有其使用的协议是每个进程在执行前申请并获得所有资源。他系统调用之前进行。</li>
<li>方法二：允许进程在没有资源时才可申请资源，一个进程可申请一些资源并使用它们，然而，在它申请更多其他资源之前，它必须释放其现已分配的所有资源。<br>这两种协议有两个主要缺点：</li>
<li>第一，资源利用率（resource utilization）可能比较低，因为很多资源可能已分配，但长时间没有被使用。</li>
<li>第二，可能发生饥饿。一个进程如需要多个常用资源，可能会永久等待，比如因为其所需要的资源中至少一个总是分配给其他的进程。</li>
</ul>
<h4 id="非抢占"><a href="#非抢占" class="headerlink" title="非抢占"></a>非抢占</h4><p>为确保这一条件不成立，可使用如下协议：<br>即可以抢占，如果一个进程占用资源并申请另一个不能立即分配的资源，那么其现已分配的资源都可被抢占，即这些资源被隐式地释放了。只有当进程获得其原有资源和所申请的新资源时，进程才可以重新执行。<br>或者说，如果一个进程申请一些资源，首先检查是否可用，如果可用就分配它们，如果不可用，那么检查这些资源是否已分配给其他等待额外资源的进程。如果是就抢占这些资源，并分配给申请进程。如果资源不可用且也不可被其他等待进程占有，那么申请进程必须等待。当一个进程处于等待时，如果其他进程申请其拥有的资源，那么该进程部分资源可以被抢占。一个进程要重新执行，他必须分配到其所申请的资源，并恢复其在等待时被抢占的资源。<br>这个协议通常用于状态可以保存和恢复的资源，如CPU寄存器和内存，一般不适用其他资源，如打印机和磁带驱动器。</p>
<h4 id="循环等待"><a href="#循环等待" class="headerlink" title="循环等待"></a>循环等待</h4><p>一个确保此条件不成立的方法是：对所有资源类型进行完全排序，且要求每个进程按递增顺序来申请资源。<br>每个进程只按照递增顺序申请资源，即一个进程开始可以申请任意数量的资源类型为Ｒｉ的实例。之后，当且仅当Ｆ（Rj）&gt;Ｆ（Ri）时，该进程可以申请资源Rj的实例。如果需要同一资源类型的多个实例，那么对它们必须一起申请。<br>例如，对于以上给定函数，一个进程如果同时需要打印机和磁带驱动器，那么就必须先申请磁带驱动器，再申请打印机。换句话说，要求当一个进程申请资源类型Rj时，必须先释放所有Ri[Ｆ（Ri）&gt;Ｆ（Rj）]</p>
<h3 id="死锁避免"><a href="#死锁避免" class="headerlink" title="死锁避免"></a>死锁避免</h3><p><strong>避免死锁的另外一种方法是获得以后如何申请资源的附加信息。</strong><br>不同的算法所要求的信息量和信息的类型上有所不同，最为简单和最为常用的模型要求每个进程说明可能需要的每种资源类型实例的最大需求。根据每个进程可能申请的每种资源类型实例的最大需求的事先信息，可以构造一个算法以确保系统绝不会进入死锁状态。这种算法定义了死锁避免（deadlock-avoidance）方法。<br>死锁避免算法动态地检测资源分配状态以确保循环等待条件不可能成立。资源分配状态是由可用资源和已分配资源，以及进程最大需求所决定的</p>
<h4 id="安全状态"><a href="#安全状态" class="headerlink" title="安全状态"></a>安全状态</h4><p>如果系统能按某个顺序为每个进程分配资源（不超过其最大值）并能避免死锁，那么系统状态就是安全的。即如果存在一个安全序列，那么系统处于安全状态。如果没有这样的顺序存在，那么系统处于不安全状态。<br>进程顺序{P1,P2,…,Pn}，如果对于每个Pi，Pi仍然可以申请的资源数小于当前可用资源加上所有进程Pj（其中j小于i）所占用资源，那么这一顺序称为安全序列。<br>在这种情况下，进程Pi所需要的资源即使不能立即使用，那么Pi等待直到所有Pj释放其资源，当它们完成时，Pi可得到其所需要的所有资源，完成其给定任务。<br>安全状态不是死锁状态，相反，死锁状态是不安全状态。然而，不是所有不安全状态都能够导致死锁状态。<br>只要状态为安全，操作系统就能避免不安全（和死锁）状态。在不安全情况下，操作系统不能阻止进程以会导致死锁的方式申请资源。进程行为控制了不安全状态。</p>
<h4 id="资源分配图算法"><a href="#资源分配图算法" class="headerlink" title="资源分配图算法"></a>资源分配图算法</h4><h4 id="银行家算法"><a href="#银行家算法" class="headerlink" title="银行家算法"></a>银行家算法</h4><p>当新进程进入系统时，它必须说明其可能需要的各种类型资源实例的最大数量，这一数量不能超过当前系统资源的总和。当用户申请一组资源时，系统必须确定这些资源的分配是否仍会使系统出于安全状态，如果是，就分配资源；否则，进程必须等待直到某个其他进程释放足够资源为止。</p>
<h3 id="死锁恢复"><a href="#死锁恢复" class="headerlink" title="死锁恢复"></a>死锁恢复</h3><p>一种措施是通知操作员死锁已发生，以便操作人员人工处理死锁。<br>另一种措施是让系统从死锁状态中自动恢复过来。</p>
<p>打破死锁有两种方法：</p>
<ul>
<li>终止或多个进程以打破循环等待。</li>
<li>从一个或多个死锁进程那里抢占一个或多个资源。</li>
</ul>
<p>进程终止：</p>
<ul>
<li>终止所有死锁进程，这种方式虽然终止了死锁循环，代价太大。</li>
<li>一次只终止一个进程直到取消死锁循环为止，这种方法的开销会很大，因为每次终止一个进程，就需要调用死锁检测算法以确定进程是否仍处于死锁。</li>
</ul>
<p>资源抢占：<br>这里有三个问题需要处理：</p>
<ul>
<li>选择一个牺牲品：抢占哪些资源和哪个进程？必须确定抢占顺序以使代价最小化。 </li>
<li>回滚：如果从一个进程那里抢占一个资源，那么应对该进程做些什么安排？必须将这个进程回滚到某个安全状态，以便以后重启进程。<br>最简单的方法是完全回滚：终止进程并重新执行。更为有效的方法是将进程回滚到足够打破死锁。另一方面，这种方法要求系统维护有关运行进程状态的更多信息。</li>
<li>饥饿：如何确保不会发生饥饿？最为常用的方法是在代价因素中加上回滚次数。</li>
</ul>
<h2 id="第八章-内存管理"><a href="#第八章-内存管理" class="headerlink" title="第八章 内存管理"></a>第八章 内存管理</h2><h4 id="基本硬件"><a href="#基本硬件" class="headerlink" title="基本硬件"></a>基本硬件</h4><p>CPU所能直接访问的存储器只有内存和处理器内的寄存器<br>CPU内置寄存器通常可以在一个CPU时钟周期内完成访问<br>完成内存访问需要多个CPU时钟周期，由于没有数据以便完成正在执行的指令，CPU通常需要暂停（stall）。解决方法是在CPU与内存之间增加高速内存，称为高速缓存（cache）。</p>
<p>还要确保操作系统不会被用户进程所访问，确保用户进程不会被其他用户进程访问。<br>其中一种可能方案为：首先确保每个进程都有独立的内存空间，需要确定进程可访问合法地址的范围，并确保进程只能访问其合法地址。通过基地址寄存器（base register）和界限地址寄存器（limit register）可以实现这种保护。<br>基地址寄存器（base register）含有最小的物理内存地址，界限地址寄存器（limit register）决定了范围的大小</p>
<p>内存空间保护的实现，是通过CPU硬件对用户模式所产生的每个地址与寄存器的地址进程比较来完成的。如果访问了不该访问的地址，则会陷入到操作系统中，并作为致命错误处理。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-03_16-42-27.jpg"></p>
<p>只有操作系统可以通过特殊的特权指令来加载基地址寄存器和界限地址寄存器<br>由于特权指令只可在内核模式下执行，而只有操作系统在内核模式下执行，所以只有操作系统可以加载基地址寄存器和界限地址寄存器。这种方案允许操作系统修改两个寄存器的值，而不允许用户程序去修改他们。<br>操作系统在内核模式下，可以无限制地访问操作系统和用户内存。因此操作系统可以将用户程序装入用户内存，在出错时输出这些程序，访问并修改系统调用的参数等。</p>
<h4 id="地址绑定"><a href="#地址绑定" class="headerlink" title="地址绑定"></a>地址绑定</h4><p>通常，程序以二进制可执行文件的形式存储在磁盘上。为了执行，程序被调入内存并放入进程空间内。</p>
<p>许多系统允许用户进程放在物理地址的任意位置。这种组合方式会影响用户程序能够使用的地址空间。在绝大多数情况下，用户程序在执行前，会经过好几个步骤<br>在这些步骤中，地址可能有不同的表示形式，<strong>源程序</strong>中的地址通常是用<strong>符号</strong>表示，<strong>编译器通常将这些符号地址绑定（bind）在可重定位的地址</strong><br><strong>链接程序或加载程序再将这些可重定位的地址绑定成绝对地址</strong>每次绑定都是从<strong>一个地址空间到另一地址空间的映射</strong>。</p>
<p>通常，将指令与数据绑定到内存地址有以下几种情况：<br><strong>编译时</strong>（compile time）：如果编译时就知道进程将在内存中的驻留地址，那么就可以生成绝对代码（absolute code）。如果将来开始地址发生变化，那么就必须重新编译代码。<br><strong>加载时</strong>（load time）：当编译时不知道进程将驻留在内存的什么地方，那么编译器就必须生成可重定位代码（reloadable code）。绑定会延迟到加载时才进行。如果开始地址发生变化。只需要重新加载用户代码已引入改变值。<br><strong>执行时</strong>（execution time）：如果进程在执行时可以从一个内存段移到另一个内存段，那么绑定必须延迟到执行时才发生。绝大多数通用计算机操作系统采用这种方法。</p>
<h4 id="逻辑地址空间和物理地址空间"><a href="#逻辑地址空间和物理地址空间" class="headerlink" title="逻辑地址空间和物理地址空间"></a>逻辑地址空间和物理地址空间</h4><p>程序生成的地址通常称为逻辑地址，而内存单元所看到的地址（即加载到内存地址寄存器中的地址）通常称为物理地址。</p>
<p><strong>编译时绑定</strong>和<strong>加载时绑定</strong>生成相同的逻辑地址和物理地址。但是，<strong>执行时绑定</strong>会导致不同的逻辑地址和物理地址。对于这种情况，通常称逻辑地址为虚拟地址。<br>由程序所生成的所有逻辑地址称为<strong>逻辑地址空间</strong>，与这些逻辑地址相对应的物理地址的集合称为<strong>物理地址空间</strong>。</p>
<p>运行时从虚拟地址到物理地址的映射由被称为<strong>内存管理单元（memory-management unit，MMU）</strong>的硬件设备来完成。<br>有很多可选择的方法来完成这种映射，比如基地址寄存器方案的推广，基地址寄存器在这里称为重定位寄存器（relocation register），用户进程所生成的地址在送交内存之前，都加上重定位寄存器的值。</p>
<p>假如，基地址为14000，那么用户对地址346的访问将映射为地址14346。<br><img src="/2021/07/12/osnote-md/Xnip2021-06-03_16-55-15.jpg"><br>用户程序绝对不会看到真正的物理地址。只有当它作为物理地址时，它才进行相对于基地址寄存器的重定位。用户程序处理逻辑地址时，内存映射硬件将逻辑地址转变为物理地址。所引用的内存地址只有在引用时才最后定位。</p>
<p>逻辑地址空间映射到单独的一套物理地址空间，这一概念对内存的管理至关重要。</p>
<h4 id="动态加载（dynamic-loading）"><a href="#动态加载（dynamic-loading）" class="headerlink" title="动态加载（dynamic loading）"></a>动态加载（dynamic loading）</h4><p>一个进程的整个程序和数据如果都必须处于物理内存中，则进程的大小受物理内存大小的限制。为了获得更好的内存空间使用率，使用动态加载（dynamic loading），即一个子程序只有在调用时才被加载。</p>
<p>所有的子程序都以可重定位的形式保存在磁盘上。主程序装入内存并执行。当一个子程序需要调用另外一个子程序的时候，调用子程序首先检查另一个子程序是否已经被加载。如果没有，可重定位的链接程序将用来加载所需要的子程序，并更新程序的地址表以反应这一变化。接着控制传递给新加载的子程序。</p>
<p>动态加载的优点是不用子程序绝不会被加载，如果存在代码使用频率比较低，如错误处理，那么这种方法特别有用。</p>
<p>动态加载不需要操作系统提供特别的支持。利用这种方法来设计程序主要是用户的责任。</p>
<h4 id="动态链接（dynamically-linking）与共享库"><a href="#动态链接（dynamically-linking）与共享库" class="headerlink" title="动态链接（dynamically linking）与共享库"></a>动态链接（dynamically linking）与共享库</h4><p>有的操作系统只支持静态链接（static linking）此时系统语言库的处理与其他目标模块一样，由加载程序合并到二进制程序镜像中。</p>
<p><strong>动态链接</strong>的概念与<strong>动态加载</strong>相似。只是这里不是将加载延迟到运行时，而是将链接延迟到运行时。这一特点通常用于系统库，如语言子程序库，如果没有这个特点，系统上的所有程序都需要一份语言库的副本</p>
<p>如果有动态链接，二进制镜像中每个库程序的应用都有一个存根（stub）。存根是一小段代码，用以指出如何定位适当的内存驻留的库程序，或如果该程序不在内存中会指出如何安装入库。存根会用子程序地址来代替自己，并开始执行子程序。因此，下次再执程序代码时，就可以直接进行，而不会因动态链接产生任何开销。</p>
<p>动态连接也可用于库更新。一个库可以被新的版本所替代，且使用该库的所有程序会自动使用新的版本。没有动态链接，所有这些程序必须重新链接以便访问。</p>
<p>为了不使程序错用新的、不兼容版本的库，程序和库将包括版本信息。多个版本的库都可以装入内存，程序通过版本信息来确定使用哪个库副本。</p>
<p>因此，只有用新库编译的程序才会收到新库的不兼容变化影响。在新程序装入之前所链接的其他程序可以继续使用老库。这种系统也称为共享库。</p>
<p>与动态加载不同，动态链接通常需要操作系统帮助。因为内存中的进程是彼此保护的，那么只有操作系统才可以检查所需子程序是否在其他进程内存空间内，或是允许多个进程访问同一内存地址。</p>
<h4 id="连续内存分配（contiguous-memory-allocation）"><a href="#连续内存分配（contiguous-memory-allocation）" class="headerlink" title="连续内存分配（contiguous memory allocation）"></a>连续内存分配（contiguous memory allocation）</h4><p>内存应该尽可能有效地分配内存的各个部分，不浪费资源。</p>
<p>内存通常分为两个区域：一个用于驻留操作系统，一个用于用户进程。操作系统可以位于低内存或高内存，影响这一决定的主要因素是中断向量的位置。由于中断向量通常位于低内存，因此程序员通常将操作系统放到低内存。</p>
<p>采用连续内存分配（contiguous memory allocation）时，每个进程位于一个连续的内存区域。</p>
<h4 id="内存映射与保护"><a href="#内存映射与保护" class="headerlink" title="内存映射与保护"></a>内存映射与保护</h4><p>通过采用重定位寄存器和界限地址寄存器可以实现保护。</p>
<p>重定位寄存器含有最小的物理地址值；界限地址寄存器含有逻辑地址的范围值。</p>
<p>这样每个逻辑地址必须小于界限地址寄存器。MMU动态将逻辑地址加上重定位寄存器的值后影射成物理地址。映射后的物理地址再送交内存单元。<br><img src="/2021/07/12/osnote-md/Xnip2021-06-03_17-18-02.jpg"></p>
<p>当CPU调度器选择一个进程然后进行上下文切换工作时，调度程序会用正确的值来初始化重定位寄存器和界限地址寄存器。CPU所产生的每一地址都需要与寄存器进程核对，所以可以保证操作系统和其他用户程序和数据不受该进程的影响。</p>
<p>重定位寄存器机制为允许操作系统动态改变提供了一个有效方法。如某驱动程序（或其他操作系统服务）不常使用便可以不必在内存中，这类代码称为暂时性操作系统代码，它们根据需要调入或调出，使用这种代码可以在程序执行时动态改变操作系统的大小。</p>
<h4 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h4><p><strong>固定大小分区</strong>。最简单的内存分配方法之一是将内存分为多个固定大小的分区。每个分区只能容纳一个进程。那么多道程序的程度会受分区数限制。如果使用这种多分区方法，当一个分区空闲时，可以从输入队列中选择一个进程调入到空闲分区。当进程终止时，其分区可以被其他进程所使用。这种方法现在已<strong>不再使用</strong>。这种固定分区方案的推广（称为MVT），它主要用于批处理环境。也可用于纯分段内存管理的分时操作系统。</p>
<p><strong>可变大小分区</strong>。在可变分区方案中，操作系统有一个表，用于记录那些内存可用和哪些内存已被占用。一开始，所有内存都可用于用户进程，因此可以作为一大块可用内存，称为孔（hole），当新进程需要内存时，为该进程查找足够大的孔，如果找到，可以从该孔进程分配所需的内存，孔内未分配的内存可用于下次再用。</p>
<p>随着进程进入系统，它们将被加入输入队列中。操作系统根据调度算法来对进程的输入队列进行排序。内存不断地分配给进程，直到下一个进程的内存需求不能满足为止，如果没有足够大的孔来装入进程，操作系统可以等到有足够大的空间，或者往下扫描输入队列以确定是否其他内存需求较小的进程可以被满足。</p>
<p>通常，一组不同大小的孔分散在内存中。当新进程需要内存时，系统为进程查找足够大的孔。如果孔太大，那么就分成两块：一块分配给新进程，另一块还回到孔集合，当进程终止时，它将释放其内存，该内存将还给孔集合。如果孔与其他孔相邻，那么将这些孔合并为大孔。这时，系统可以检查是否有进程在等待内存空间，新合并的内存空间是否满足等待进程。</p>
<p>那么我们如何寻找孔呢</p>
<p><strong>首次适应</strong>（first-fit）：分配<strong>第一个足够大</strong>的孔，查找可以从头开始，也可以从上次首次适应结束时开始。一旦找到足够大的空闲孔，就可以停止。</p>
<p><strong>最佳适应</strong>（best-fit）：分配<strong>最小的足够大</strong>的孔。必须查找整个列表，除非列表按照大小排序。这种方法可以产生最小剩余孔。</p>
<p><strong>最差适应</strong>（worst-fit）：分配<strong>最大</strong>的孔，同样必须查找整个列表，除非列表按照大小排序。这种方法可以产生最大剩余孔。该孔可能比最佳适应方法产生的最小剩余孔更有用。</p>
<p>模拟结果显示：首次适应和最佳适应方法在执行时间和利用空间方面都好于最差适应方法。首次适应和最佳适应方法在利用空间方面难分伯仲，首次适应方法更快些。</p>
<h4 id="碎片（fragmentation）"><a href="#碎片（fragmentation）" class="headerlink" title="碎片（fragmentation）"></a>碎片（fragmentation）</h4><p>首次适应和最佳适应算法都有<strong>外部碎片</strong>问题（external fragmentation）。随着进程装入和移出内存，空闲内存空间被分割为小分段，当所有总的空用内存之和可以满足请求但并不连续，这就出现了外部碎片问题。最坏的情况下，每两个进程之间就有空闲块（或浪费）。</p>
<p>在首次适应和最佳适应之间的选择可能会影响碎片的量。另一个影响因素是从空闲块的哪端开始分配。不管使用哪种算法，外部碎片始终是个问题。</p>
<p>内存碎片可以是内部的，也可以是外部的。如果内存以固定大小的块为单元来分配，进程所分配的内存可能比所要的要大。这两个数字之差称为<strong>内部碎片</strong>（internal fragmentation）这部分内存在分区内，但又不能使用。</p>
<p>一种解决外部碎片问题的方法是<strong>紧缩</strong>（compaction），紧缩的目的是移动内存内容，以便所有空闲空间合并成一整块。但是紧缩并非总是可能的。如果重定位是静态的，并且在汇编时或装入时进行的，那么就不能紧缩。紧缩仅在重定位是动态的并在运行时可采用。如果地址被动态重定位，可以首先移动程序和数据，然后再跟据新基地址基地的值来改变址寄存器。如果采用紧缩，还要评估其开销，最简单的合并算法是简单地将所有进城移到内存的一端，而将所有的孔移到内存的另一端，以生成一个大的空闲块。这种方案开销较大。</p>
<p>另一种解决方法外部碎片问题的方法是<strong>允许物理地址为非连续</strong>的。这样只要有物理内存就可以为进程分配。这种方案有两种互补的实现技术：<strong>分页和分段</strong>。这两种技术也可以合并。</p>
<p><em><strong>分页产生内部碎片，分段产生外部碎片</strong></em></p>
<h4 id="分页（paging）"><a href="#分页（paging）" class="headerlink" title="分页（paging）"></a>分页（paging）</h4><p>分页（paging）内存管理方案允许进程的物理地址空间可以使非连续的。</p>
<p>传统上，分页支持一直是由硬件来处理的。最近的设计是通过将硬件和操作系统相配合来实现分页。</p>
<h4 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h4><p>实现分页的基本方法设计将物理内存分为固定大小的块，称为帧（frame）；而将逻辑内存也分为同样大小的块，称为页（page）。当需要执行进程时，其page从备份存储中调入到可用的内存frame中。外围存储也分为固定大小的块，其大小与帧相同。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-03_17-36-12.jpg"></p>
<p>由CPU生成个每个地址分为两个部分：<strong>页号</strong>（p）和<strong>页位移</strong>（d）。<strong>页号作为页表的索引，页表包含每页所在物理内存的基地址，这些基地址与页偏移的组合形成物理地址，就可送交物理单元。</strong></p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-03_18-02-05.jpg"></p>
<p>页大小（与帧大小一样）是由硬件来决定的。通常为2的幂。选择页的大小为2的幂可以方便的将逻辑地址转换为页号和页偏移。如果逻辑地址空间为2m，且页大小为2n单元，那么逻辑地址的高m−n位表示页号（页表的索引），而低n位表示页偏移。每页大小从512B到16MB不等。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-03_18-03-27.jpg"></p>
<p><strong>设页大小为a，根据页号p得到基地址f，页偏移为d，则物理地址为f∗a+d</strong></p>
<p>分页是一种动态重定位。每个逻辑地址有分页硬件绑定为一定的物理地址。采用分页类似于使用一组基（重定位）地址寄存器，每个基地址对应这一个内存帧。</p>
<p>采用分页技术<strong>不会产生外部碎片</strong>：每个帧都可以分配给需要它的进程。不过分页<strong>有内部碎片</strong>。</p>
<p>每个页表的条目通常为4B，不过这是可变的，一个32位的条目可以指向232个物理帧的任何一个，如果帧为4KB，那么具有4B条目的系统可以访问244B大小。</p>
<p>当系统进程需要执行时，它将检查该进程的大小（按页计算）。进程的每页都需要一帧。因此，如果进程需要n页，那么至少应有n个帧。如果有那么就分配给新进程。进程的第一页装入一个已分配的帧，帧号放入进程的页表中。下一页分配给另一帧，其帧号也放入进程的页表中。</p>
<p>分页的一个重要特点是用户视角的内存和实际的物理内存的分离。用户程序将内存作为一整块来处理，而且它只包括这一个进程。事实上，一个用户程序与其他程序一起，分布在物理内存上。</p>
<p>用户视角的内存和实际的物理内存的差异是通过地址转换硬件协调的。逻辑地址转换为物理地址，这种映射是用户所不知道的，但是受操作系统所控制。注意用户进程根据定义是不能访问非它所占用的内存的。它无法访问其页表所规定之外的内存，页表只包括进程所拥有的那些页。</p>
<p>由于操作系统管理物理内存，它必须知道物理内存的分配细节：哪些帧已占用，哪些帧可用，总共有多少帧等。这些信息通常保存在帧表中。在帧表（frame table）中，每个条目对应一个帧，以表示该帧是空闲还是已占用，如果被占用，是被哪个进程的哪个页所占用。</p>
<p>另外，操作系统必须意识到用户进程是在用户空间内执行，且所有逻辑地址必须映射到物理地址。如果用户执行一个系统调用（如进行I/O），并提供地址作为参数，那么这个地址必须映射成物理地址。操作系统为每个进程维护一个页表副本，就如同它需要维护指令计数器和寄存器的内容一样。当操作系统必须手工将逻辑地址映射成物理地址时，这个副本可用来将逻辑地址转换为物理地址。当一个进程可分配到CPU时，CPU调度程序可以根据该副本来定义硬件页表。因此，分页增加了切换时间。</p>
<h4 id="硬件支持"><a href="#硬件支持" class="headerlink" title="硬件支持"></a>硬件支持</h4><p>每个操作系统都有自己的方法来保存页表。绝大多数都为每个进程分配一个页表。页表的指针与其他寄存器的值（如指令计数器）一起存入进程控制块。当调度程序需要启动一个程序时，它必须首先装入用户寄存器，并根据所保存的用户页表来定义正确的硬件页表值。</p>
<p>页表的硬件实现有很多方法。最为简单的是将页表作为一组专用寄存器（register）来实现。这些寄存器应用高速逻辑电路来构造，以便有效的进行分页地址的转换。由于对内存的每次访问都要经过分页表，因此效率很重要。CPU装入或修改页表寄存器的指令是特权级的，因此只有操作系统才可以修改内存映射图。</p>
<p>如果页表比较小（例如256个条目），页表使用寄存器还是比较合理的。但是，绝大多数当代计算机都允许页表非常大（如100万个条目）。对于这些机器，采用快速寄存器来实现页表就不可行了，因而需要将页表放在内存中，并将<strong>页表基寄存器（page-table base register，PTBR）</strong>指向页表。改变页表，只需要改变这一寄存器就可以了，这也大大降低了切换时间。</p>
<p>采用这种方法的问题是访问用户内存位置需要一些时间。如果要访问位置i，那么必须先用PTBR中的值再加上页号i的偏移，来查找页表。这一任务需要内存访问，根据所得的帧号，再加上页偏移，就得到了真实的物理地址，接着访问内存中所需的位置。采用这种方法，访问一个字节需要两次内存访问（一次用于页表条目，一次用于字节），这样内存访问的速度就减半，在绝大多数情况下这种延迟是无法忍受的。</p>
<p>对这一问题的标准解决方案是采用小但专用快速的硬件缓冲，这种缓冲称为<strong>转换表缓冲区（translation look-aside buffer，TLB）</strong>。TLB是关联的快速内存。TLB条目由两部分组成：键（标签）和值。当关联内存根据给定值查找时，它会同时与所有键进行比较。如果找到条目，那么就得到相应的值域。这种查找方式比较快，不过硬件也比较昂贵，通常，TLB中的条目数并不多，通常在64~1024之间。</p>
<p>TLB与页表一起按如下方式使用：TLB只包括页表中的一小部分条目。当CPU产生逻辑地址后，其页号提交给TLB。如果页码不在TLB中（称为TLB失效），那么就需要访问页表。将页号和帧号增加到TLB中。如果TLB中的条目已满，那么操作系统会选择一个来替换。替换策略有很多，从最近最少使用替换（LRU）到随机替换等。另外，有的TLB允许有些条目固定下来。通常内核代码的条目是固定下来的。</p>
<p>有的TLB在每个TLB条目中还保存地址空间标识码（address-space identifier，ASID）。ASID可用来唯一标识进程，并为进程提供地址空间保护。当TLB试图解析虚拟页号时，它确保当前运行进程的ASID与虚拟页相关的ASID相匹配。如果不匹配，那么就作为TLB失效。除了提供地址空间保护外，ASID允许TLB同时包含多个进程的条目。如果TLB不支持独立的ASID，每次选择一个页表时（例如，上下文切换时），TLB就必须被冲刷（flushed）或删除，以确保下一个进程不会使用错误的地址转换。<br><img src="/2021/07/12/osnote-md/Xnip2021-06-03_18-21-13.jpg"></p>
<p>页号在TLB中被查找到的百分比称为命中率。</p>
<p>80%的命中率意味着有80%的时间可以在TLB中找到所需的页号。</p>
<h4 id="保护"><a href="#保护" class="headerlink" title="保护"></a>保护</h4><p>在分页环境下，内存保护是通过与每个帧相关联的保护为来实现的。通常，这些位保存在页表中。</p>
<p><strong>可以用一个位来定义一个页是可读写还是只读的</strong>。每次地址引用都要通过页表来查找正确的帧码，在计算物理地址的同时，可以检查保护位来验证。对只读页进行写操作会向操作系统产生硬件陷阱(trap)（或内存保护冲突）。</p>
<p>可以很容易的扩展这一方法以提供更细致的保护，可以创建硬件以提供只读、读写、只执行保护。或者，通过为每种访问情况提供独立保护位，实现这些访问的各种组合；非法访问会被操作系统捕捉到。</p>
<p>还有一个位通常与页表中的每一条目相关联：有效-无效位。有效，表示相关的页在进程的逻辑地址空间内，因此是合法的页；无效，表示相关的页不在进程的逻辑地址空间内。通过使用有效-无效位可以捕捉非法地址。操作系统通过对该位可以允许或不允许对某页的访问。</p>
<p>有些系统提供硬件如页表长度寄存器（page-table length register，PTLR）来表示页表的大小，该寄存器的值可用于检查每个逻辑地址以验证其是否位于进程的有效范围内，如果检测无法通过，会被操作系统捕获。</p>
<h4 id="共享页"><a href="#共享页" class="headerlink" title="共享页"></a>共享页</h4><p>分页的优点之一在于可以共享公共代码。</p>
<p>可重入代码是不能自我修改的代码，它从不会在执行期间改变。两个或多个进程可以在相同的时间执行相同的代码。每个进程都有它自己的寄存器副本和数据存储，以控制进程执行的数据。两个不同进程的数据也将不同。</p>
<p>共享代码的只读特点不能只通过正确代码来保证，需要操作系统来强制实现。</p>
<h4 id="分段（segmentation）"><a href="#分段（segmentation）" class="headerlink" title="分段（segmentation）"></a>分段（segmentation）</h4><p>之前讲了采用分页内存管理，但是他有一个不可避免的问题，就是用户视角的内存和实际物理内存的分离。</p>
<h4 id="基本方法-1"><a href="#基本方法-1" class="headerlink" title="基本方法"></a>基本方法</h4><p>用户通常愿意将内存看作是一组不同长度的段的集合，这些段之间并没有一定的顺序。</p>
<p>分段（segmentation）就是支持这种用户视角内存管理方法。逻辑地址空间由一组段组成的。每个段都有名称和长度。地址指定了段名称和段内偏移。因此用户通过两个量来指定地址：**段名称(segment-number)<strong>和</strong>偏移(offset)**。</p>
<p>注意这一方案与分页的对比。在分页中，用户只指定一个地址，该地址通过硬件分为页码和偏移（高x位为页码，低n-x为偏移，或者反之）。</p>
<p>但是段是编号的，是通过段号而不是段名来引用的。因此，逻辑地址由有序对组成：&lt;segment−number,offset&gt;</p>
<p>通常，在编译用户程序时，编译器会自动根据输入程序来构造段。</p>
<p>一个C编译器可能会创建如下段：</p>
<ul>
<li>代码</li>
<li>全局变量</li>
<li>堆（内存从堆上分配）</li>
<li>每个线程采用的栈</li>
<li>标准的C库函数</li>
</ul>
<p>在编译时链接的库可能分配为不同的段。加载程序时会装入所有这些段，并为他们分配段号。</p>
<h5 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h5><p>用户虽然现在能够通过二维地址来引用程序中的对象，但是实际物理地址内存仍然是一维序列字节。因此，必须定义一个实现方式，以便将二维的用户定义地址映射为一维物理地址。这个地址是通过段表（segment table）来实现的。段表的每个条目都有段基地址和段界限。段基地址包含该段在内存中的开始物理地址，而段界限指定该段的长度。</p>
<p>一个逻辑地址由两部分组成：段号s和段内的偏移d。段号用来做段表的索引，逻辑地址的偏移d用位于0和段界限之间。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-03_18-31-48.jpg"><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/beyond_2016/article/details/81358067">https://blog.csdn.net/beyond_2016/article/details/81358067</a></p>
<h5 id="段页式"><a href="#段页式" class="headerlink" title="段页式"></a>段页式</h5><p>关于段页式在实际中使用的真实流程<br><strong>逻辑地址&lt;段号，偏移&gt;  -&gt;  虚拟地址&lt;页号，偏移&gt;  -&gt;  物理地址&lt;物理页号，偏移&gt;</strong></p>
<h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><h4 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h4><p>之前所介绍的内存管理算法都是基于一个基本要执行指令必须在物理内存中，满足这一要求的第一种方法是整个进程放在内存中。动态载入能帮助减轻这一限制，但是它需要程序员特别小心地做一些额外的工作。<br>指令必须都在物理内存内的这一限制，似乎是必须和合理的，但也是不幸的，因为这使得程序的大小被限制在物理内存的大小内。事实上，研究实际程序会发现，许多情况下并不需要将整个程序放到内存中。即使在需要完整程序的时候，也并不是同时需要所有的程序。·<br>虚拟内存（virtual memory）将用户逻辑内存和物理内存分开。这在现有物理内存有限的情况下，为程序员提供了巨大的虚拟内存。<br>根据之前所述，物理地址可以按页幁来组织，且分配给进程的物理页帧也可能不是连续的。这就需要内存管理单元（MMU）将逻辑页映射到内存的物理页帧。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-03_18-35-55.jpg"></p>
<p>如上图显示，运行随着动态内存的分配，堆可向上生长。类似地，还允许随着子程序的不断调用，栈可以向下生长。堆与栈之间的巨大空白空间(或hole)为虚拟地址的一部分，只有在堆与栈生长的时候，才需要实际的物理页。包括空白的虚拟地址空间成为稀地址空间，采用稀地址空间的优点是：随着程序的执行，栈或者堆段的生长或需要载入动态链接库（或共享对象）时，这些空白可以填充。<br>除了将逻辑内存与物理内存分开，虚拟内存也允许文件和内存通过共享页而为两个或者多个进程所共享，这样带来了如下优点</p>
<p>    通过将共享对象映射到虚拟地址空间，系统库可为多个进程所共享。虽然每个进程都认为共享库是其虚拟地址空间的一部分，而共享库所用的物理内存的实际页是为所有进程所共享。通常，库是按制度方式来链接每个进程的空间的。<br>    类似的，虚拟内存允许进程共享内存。两个或者多个进程之间可以通过使用共享内存来相互通信。虚拟内存允许一个进程创建内存区域，以便与其他进程进行共享。共享该内存区域的进程认为它是其虚拟地址空间的一部分，而事实上这部分是共享的。<br>    虚拟内存可允许在用系统调用fork()创建进程期间共享页，从而加快进程的创建。</p>
<h4 id="按需调页"><a href="#按需调页" class="headerlink" title="按需调页"></a>按需调页</h4><p>一个执行程序从磁盘载入内存的时候有两种方法。</p>
<ol>
<li>选择在程序执行时，将整个程序载入到内存中。不过这种方法的问题是可能开始并不需要整个程序在内存中。如有的程序开始时带有一组用户可选的选项。载入整个程序，也就将所有选项的执行代码都载入到内存中，而不管这些选项是否使用。</li>
<li>另一种选择是在需要时才调入相应的页。这种技术称为按需调页(demand paging)，常为虚拟内存系统所采用。<br>按需调页系统看类似于使用交换的分页系统，进程驻留在第二级存储器上（通常为磁盘）。当需要执行进程时，将它换入内存。不过，不是讲整个进程换入内存，而是使用懒惰交换(lazy swapper)。懒惰交换只有在需要页时，才将它调入内存。交换程序(swapper)对整个进程进行操作，而调页程序(pager)只是对进程的单个页进行操作。因此， 在讨论有关按需调页时，需要使用调页程序而不是交换程序。</li>
</ol>
<h5 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h5><p>当换入进程时，调页程序推测在该进程再次换出之前使用到的哪些页，仅仅把需要的页调入内存。从而减少交换时间和所需的物理内存空间。</p>
<p>这种方案需要硬件支持区分哪些页在内存，哪些在磁盘。采用有效/无效位来表示。当页表中，一个条目的该位为有效时，表示该页合法且在内存中；反之，可能非法，也可能合法但不在内存中。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-03_18-43-06.jpg"></p>
<p>如果进程从不试图访问标记为无效的页，那么并没有什么影响，因此，如果推测正确且只调入所有真正需要的页，那么进程就可如同所有页都调入内存一样正常运行。</p>
<p>当进程试图访问这些尚未调入内存的页时，会引起页错误陷阱（page-fault trap）。这种情况的处理方式如下：</p>
<ol>
<li>检查进程的内部页表（通常与PCB一起保存）。以确定该引用是的合法还是非法的地址访问。</li>
<li>如果非法，则终止进程；如果引用有效但是尚未调入页面，则现在进行调入。</li>
<li>找到一个空闲帧（如，从空闲帧表中选取一个）。</li>
<li>调度一个磁盘操作，以便将所需页调入刚分配的帧</li>
<li>磁盘读操作完成后，修改进程的内部表和页表，表示该页已在内存中。</li>
<li>重新开始因陷阱而中断的指令。</li>
</ol>
<p>如果没有空闲帧时该如何处理呢？</p>
<p>页替换：在内存中找到一些不再使用的页，将它换出去。</p>
<p>支持按需调页的硬件与分页和交换的硬件一样：<br><strong>页表</strong>：该表通过有效-无效位或保护位的特定值<br><strong>次级存储器</strong>：该次级存储器用来保存不再内存中的页。次级存储器通常为快速磁盘。它通常成为交换设备，用于交换的这部分磁盘称为交换空间</p>
<h5 id="按需调页的性能"><a href="#按需调页的性能" class="headerlink" title="按需调页的性能"></a>按需调页的性能</h5><p>其中页错误时间有很多，主要是下面三种：</p>
<ol>
<li>处理页错误中断</li>
<li>读入页（页换入时间）</li>
<li>重新启动进程</li>
</ol>
<p>按需调页的例子</p>
<p>内存存取时间 =200 ns  平均页错误服务时间 =8 ms  EAT=(1−p)×200 ns+p×8000000<br>如果每次1000次访问中有1次页错误，则EAT=8.2ns。即，因按需调页而慢40倍，如果需要性能降低不超过10%，则需要p&lt;0.0000025</p>
<p>因此来看，对于按需调页，<strong>降低页错误率</strong>至关重要。</p>
<p>另外是对交换空间的处理的使用。磁盘IO到交换空间通常比到文件系统要快，因为交换空间是按大块进行分配，并不使用文件查找和间接分配方法。<strong>因此，在进程开始时将整个文件镜像复制到交换空间，并从空间交换执行按页调度，那么有可能获得更好的性能</strong>。</p>
<p>另一种选择是开始时从文件系统进行按需调页，但置换出来的页写入交换空间，而后的调页则从交换空间中读取。这种方法确保只有需要的页才从文件系统中调入，又可以保证一定的性能。</p>
<h4 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h4><p>**写时复制Copy-on-Write (COW)**运行父进程与子进程开始时共享同一页面，这些页面标记为写时复制页，即如果任何一个进程需要对页进行写操作，那就复制一份共享页拿出来用。</p>
<p>写时复制所需一个空闲缓冲池，系统通常用按需填零(zero-fill-on-demand)的技术分配这些页。按需填零在需要分配之前先填零，因此清除了以前的内容。</p>
<p>下面的两个过程提箱了进程1修改C前后的物理内存的情况。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-03_18-53-22.jpg"></p>
<h4 id="页面置换"><a href="#页面置换" class="headerlink" title="页面置换"></a>页面置换</h4><p><strong>操作系统为何要进行页面置换呢？这是由于操作系统给用户态的应用程序提供了一个虚拟的“大容量”内存空间，而实际的物理内存空间又没有那么大。所以操作系统就就“瞒着”应用程序，只把应用程序中“常用”的数据和代码放在物理内存中，而不常用的数据和代码放在了硬盘这样的存储介质上。如果应用程序访问的是“常用”的数据和代码，那么操作系统已经放置在内存中了，不会出现什么问题。但当应用程序访问它认为应该在内存中的的数据或代码时，如果这些数据或代码不在内存中，则根据上文的介绍，会产生缺页异常。这时，操作系统必须能够应对这种缺页异常，即尽快把应用程序当前需要的数据或代码放到内存中来，然后重新执行应用程序产生异常的访存指令。如果在把硬盘中对应的数据或代码调入内存前，操作系统发现物理内存已经没有空闲空间了，这时操作系统必须把它认为“不常用”的页换出到磁盘上去，以腾出内存空闲空间给应用程序所需的数据或代码。</strong></p>
<p>操作系统迟早会碰到没有内存空闲空间而必须要置换出内存中某个“不常用”的页的情况。如何判断内存中哪些是“常用”的页，哪些是“不常用”的页，把“常用”的页保持在内存中，在物理内存空闲空间不够的情况下，把“不常用”的页置换到硬盘上就是页面置换算法着重考虑的问题。容易理解，一个好的页面置换算法会导致缺页异常次数少，也就意味着访问硬盘的次数也少，从而使得应用程序执行的效率就高。</p>
<p>置换基本流程</p>
<ol>
<li>查找需要页在磁盘上的位置。</li>
<li>查找一空闲帧：</li>
<li>如果有空闲帧，那么就使用它</li>
<li>如果没有空闲帧，那么就是用页置换算法选择一个“牺牲”帧（victim frame）</li>
<li>将牺牲帧的内容放到磁盘上，改变页表和帧表。</li>
<li>将所需页读入（新）空闲帧，改变页表和帧表。</li>
<li>重启用户进程。</li>
</ol>
<p>如果没有帧空闲，那么需要采用两个页传输（一个换出，一个换入）。可以通过使用修改位或脏位以降低额外开销。每当页内的任何字或字节被写入时，硬件就会设置该页的修改位以表示该页已被修改。这样的话，磁盘上页的副本的内容没有必要重写。</p>
<p>页置换是按需调页的基础。为实现按需调页，必须解决两个主要问题：必须开发**帧分配算法(frame-allocation algorithm)<strong>和</strong>页置换算法(page-replacement algorithm)**。如果在内存中有多个进程，那么必须决定为每个进程各分配多少帧。而且，当需要页置换时，必须选择要置换的帧。</p>
<p>可以这样来评估一个算法：针对特定内存引用序列，运行某个置换算法，并计算出页错误的数量。内存的引用序列成为引用串(reference string)。</p>
<p>第一，对给定页大小（页大小通常由硬件或系统来决定），只需要考虑页码，而不需要完整的地址。<br>第二，如果有一个页p的引用，那么任何紧跟着对页p的引用绝不会产生页错误。页p在第一次引用时已在内存中，任何紧跟着的引用绝不会出错。</p>
<h5 id="FIFO页置换"><a href="#FIFO页置换" class="headerlink" title="FIFO页置换"></a>FIFO页置换</h5><p>该算法总是淘汰最先进入内存的页，即选择在内存中驻留时间最久的页予以淘汰。FIFO算法只是在应用程序按线性顺序访问地址空间时效果才好，否则效率不高。因为那些常被访问的页，往往在内存中也停留得最久，结果它们因变“老”而不得不被置换出去。FIFO算法的另一个缺点是，它有一种异常现象（Belady现象），即在增加放置页的页帧的情况下，反而使缺页异常次数增多。</p>
<h5 id="最优-Optimal-置换"><a href="#最优-Optimal-置换" class="headerlink" title="最优(Optimal)置换"></a>最优(Optimal)置换</h5><p>所选择的被淘汰页面，将是以后永不使用的或许是在最长的未来时间内不再被访问的页面。采用最佳置换算法，通常可保证获得最低的缺页率。但由于操作系统其实无法预知一个应用程序在执行过程中访问到的若干页中，哪一个页是未来最长时间内不再被访问的，因而该算法是无法实际实现，但可以此算法作为上限来评价其它的页面置换算法。</p>
<h5 id="LRU（Least-Recently-Used）页置换"><a href="#LRU（Least-Recently-Used）页置换" class="headerlink" title="LRU（Least Recently Used）页置换"></a>LRU（Least Recently Used）页置换</h5><p>FIFO置换算法性能之所以较差，是因为它所依据的条件是各个页调入内存的时间，而页调入的先后顺序并不能反映页是否“常用”的使用情况。</p>
<p>最近最久未使用（LRU）置换算法，是根据页调入内存后的使用情况进行决策页是否“常用”。由于无法预测各页面将来的使用情况，只能利用“最近的过去”作为“最近的将来”的近似，因此，LRU置换算法是选择最近最久未使用的页予以淘汰。该算法赋予每个页一个访问字段，用来记录一个页面自上次被访问以来所经历的时间t,，当须淘汰一个页面时，选择现有页面中其t值最大的，即最近最久未使用的页面予以淘汰。</p>
<p>算法的实现：由于LRU算法淘汰的是上次使用距离t时刻最远的页，故需记录这个距离。</p>
<h5 id="近似LRU页置换"><a href="#近似LRU页置换" class="headerlink" title="近似LRU页置换"></a>近似LRU页置换</h5><p>很少有计算机系统能够提供足够的硬件来支持真正的LRU页置换，因此必须使用其他置换算法。然而，许多系统都通过应用为方式提供一定支持，页表内的每项都关联着一个引用位(reference bit)，每当引用一个页时，相应页表的引用位就会被引脚置位。如添加一个8bit的引用位（极端情况下只有一个引用位，即二次机会算法）。每个时钟都向右移位，引用的话高位为1，否则为0。</p>
<p>开始，操作系统会将所有引用位都清零。随着用户进程的执行，与引用页相关联的引用位被硬件置位。通过检查引用位，能确定那些用过而那些没用过。这种部分排序信息导致了许多近似LRU算法的页置换算法。</p>
<ul>
<li><p>附加引用位算法：可以为位于内存中的每个表中的页保留一个8bit的字节。操作系统把每个页的引用位转移到其8bit字节的高位，而将其他位右移，并抛弃最低位。如果将8bit字节作为无符号整数，那么具有最小值的页为LRU页，且可以被置换。</p>
</li>
<li><p>二次机会算法：二次机会置换的基本算法是FIFO置换算法。当要选择一个页时，检查其引用位。如果其值为0，那么就直接置换该页。如果引用位为1，那么就给该页第二次机会，并选择下一个FIFO页。当一个页获得第二次机会时，其引用位清零。且其到达时间设为当前时间。因此获得第二次机会的页，在所有其他页置换之前，是不会被置换的。另外，如果一个页经常使用以致于其引用位总是得到设置，那么它就不会被置换。一种实现二次机会算法的方法是采用循环队列。用一个指针表示下次要置换哪个页。当需要一个帧时，指针向前移动直到找到一个引用位为0的页。在向前移动时，它将清除引用位。</p>
</li>
<li><p>增强型二次机会算法: 通过将引用位和修改位作为一个有序对来考虑，能增强二次机会算法。有下面四种可能类型：</p>
<ol>
<li>(0,0)最近没有使用且也没有修改。—用于置换的最佳页</li>
<li>(0,1)最近没有使用但修改过。—不是很好，因为在置换之前需要将页写出到磁盘</li>
<li>(1,0)最近使用过但没有修改  —它有可能很快又要被使用</li>
<li>(1,1)最近使用过且修改过    —它有可能很快又要被使用，且置换之前需要将页写出到磁盘</li>
</ol>
</li>
</ul>
<p>当页需要置换时，每个页都属于这四种类型之一。置换在最低非空类型中所碰到的页，可能要多次搜索整个循环队列。</p>
<h5 id="页缓冲算法"><a href="#页缓冲算法" class="headerlink" title="页缓冲算法"></a>页缓冲算法</h5><p>系统通常保留一个空闲帧缓冲池。当出现页错误时，会像以前一样选择一个牺牲帧，在牺牲帧写出之前，所需要的页就从缓冲池中读到空闲内存。</p>
<h4 id="帧分配"><a href="#帧分配" class="headerlink" title="帧分配"></a>帧分配</h4><h5 id="帧的最少数量"><a href="#帧的最少数量" class="headerlink" title="帧的最少数量"></a>帧的最少数量</h5><p>如何在各个进程之间分配一定的空闲内存？<br>简单办法是将帧挂在空闲帧链表上，当发生页错误之时即进行分配。进程终止时帧再次放回空闲帧链表。<br>帧分配策略受到多方面限制。<br>例如， 分配数不能超过可用帧数，也必须分配至少最少数量。保证最少量的原因之一是性能。页错误增加会减慢进程的执行。并且，在指令完成前出现页错误，该指令必须重新执行。所以有足够的帧至关重要。<br>每个进程帧的最少数量由体系结构决定，而最大数量是由可用物理内存数量决定。</p>
<h5 id="分配算法"><a href="#分配算法" class="headerlink" title="分配算法"></a>分配算法</h5><ul>
<li>平均分配，每个进程一样多</li>
<li>按进程大小使用比例分</li>
<li>按进程优先级分</li>
<li>大小和优先级组合分</li>
</ul>
<h5 id="全局分配和局部分配"><a href="#全局分配和局部分配" class="headerlink" title="全局分配和局部分配"></a>全局分配和局部分配</h5><p>全局置换允许进程从所有帧集合中选择一个进行置换，而不管该帧是否已分配给其他进程，即它可以从其他进程抢夺帧，比如高优先级抢夺低优先级的帧；局部分配则要求每个进程只能从自己的分配帧中分配。</p>
<p>局部置换要求每个进程仅从其自己的分配帧中进行选择<br>全局置换通常有更好的吞吐量，且更为常用。一个问题是不能控制页错误率。因为局部置换不能使用其他进程的不常用的内存。</p>
<h4 id="系统颠簸"><a href="#系统颠簸" class="headerlink" title="系统颠簸"></a>系统颠簸</h4><p>如果一个进程在换页上用的时间多于执行时间，那么这个进程就在颠簸（thrashing），颠簸其实就是频繁的页调度行为。</p>
<h5 id="系统颠簸的原因"><a href="#系统颠簸的原因" class="headerlink" title="系统颠簸的原因"></a>系统颠簸的原因</h5><p>如果一个进程没有分配到足够的页，那么就会导致页置换不断的发生，这将导致：</p>
<p>低CPU利用率<br>低CPU利用率导致系统认为需要引入新进程，增加多道程序的程度。<br>进程分配到的帧会更少<br>死循环</p>
<h4 id="内存映射文件"><a href="#内存映射文件" class="headerlink" title="内存映射文件"></a>内存映射文件</h4><p>文件的内存映射（memory-mapping）允许一部分虚拟内存与文件逻辑相关联。这样的结果是能够通过虚拟内存技术来将文件IO作为普通内存来访问。利用虚拟内存技术将文件I/O作为普通内存访问的方法叫做文件的内存映射。</p>
<p>开始的文件访问按普通请求页面调度来进行，会产生页错误。这样，一页大小的部分文件从文件系统读入物理页，以后文件的读写就按照通常的内存访问来处理</p>
<p>对于映射到内存的文件进行读写操作可能不会及时的更新到磁盘的文件当中。更新文件的操作通常由两种方式：<br>一、通过定期检查内存映射页是否改变来判断是否应该写磁盘<br>二、在关闭文件的时候将内存映射页写回磁盘，并从进程的虚拟内存中删除。</p>
<h4 id="内核内存的分配"><a href="#内核内存的分配" class="headerlink" title="内核内存的分配"></a>内核内存的分配</h4><p>当用户态进程需要额外内存时，可以从内核所维护的空闲页帧链表中获取页。但是，内核内存的分配通常是从空闲内存池中获取的。</p>
<p>内核内存的分配与普通用户（从进程空闲链表中获取）不同：</p>
<p>    内核分配内存时，有时需要的空间不到一页。因此，需要谨慎的分配内存，减少浪费。<br>    有些硬件需要直接和物理内存交互，因此需要分配连续的物理页</p>
<ul>
<li>buddy 系统</li>
<li>slab 分配</li>
</ul>
<h2 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h2><p>文件系统和两个不同部分组成：一组文件和目录结构。<br><img src="/2021/07/12/osnote-md/Xnip2021-06-04_13-16-58.jpg"></p>
<h4 id="文件概念"><a href="#文件概念" class="headerlink" title="文件概念"></a>文件概念</h4><p>文件是记录在外存上得相关信息的具有名称的集合，具有连续的逻辑地址空间。通常，文件表示数据和程序。</p>
<p>数据文件可以包括，数字、字符、字符串或二进制。文件可以是自由形式，如文本文件，也可以具有严格的格式。</p>
<p>文件必须具有可以长期信息存储的性质、必须能够保存大容量数据、在进程终止后信息能够保留下来、能够多进程并发访问文件中的信息。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-04_13-19-24.jpg"></p>
<h5 id="文件属性"><a href="#文件属性" class="headerlink" title="文件属性"></a>文件属性</h5><ul>
<li>名称：按人们易读的方式保存的信息</li>
<li>标识符：用户不可读，用于在文件系统内进行该文件的标识</li>
<li>类型：用于操作系统辨认并执行</li>
<li>位置：文件位于硬盘上的位置的指针</li>
<li>大小：大小</li>
<li>保护：控制谁可以读、写、执行</li>
<li>时间、日期和用户标识：创建，上次修改，上次访问时间等信息，用于保护，安全，使用跟踪。</li>
</ul>
<p>文件的属性信息保存在硬盘上的目录结构中.而目录结构也保存在外存上。</p>
<h5 id="文件的操作-File-Operations"><a href="#文件的操作-File-Operations" class="headerlink" title="文件的操作(File Operations)"></a>文件的操作(File Operations)</h5><ul>
<li>创建：包含到文件系统中找到空间和在目录中为文件创建一个条目</li>
<li>写：需要执行系统调用。另外需要搜索目录查找文件位置和为该文件维护一个写位置的指针并在发生写操作时不断更新指针位置</li>
<li>读：需要执行系统调用。过程同写，需要搜索过程和维护读指针的位置</li>
<li>重定位：设置文件位置指针为给定值。该操作不需要真正的IO操作，也叫做寻址（seek）</li>
<li>删除：搜索，释放相关空间，并删除相应条目。</li>
<li>截短文件（truncate）：将文件长度设置为0KB，并释放相关空间，但不改变其他属性（不删除条目）。如截短一个命名为a.txt的文本文件后，它的大小会变为0kb，但文件名和其他属性可能没有变化。<br>上述的操作都涉及到为给定的文件搜索其在目录中的相关位置，为了避免不断搜索，在首次使用文件时，和使用完毕文件时，还需要执行两个操作：</li>
<li>打开（open）：为系统调用。将执行搜索，并将相关文件的所有内容都移动到内存中，需要操作时，通过该表的索引指定文件，并直接在内存中进行操作，从而避免了重新搜索和IO操作。</li>
<li>关闭（close）：为系统调用。将文件的索引从信息表中删除，并将相关信息从内存写到外存。<br>    操作系统维护包含所有打开文件的信息表（open-file table），当需要文件操作时，通过该表的索引指定文件。</li>
</ul>
<p>对于打开的文件，能够得到如下的信息：</p>
<ul>
<li>文件指针：读和写操作的指针</li>
<li>文件打开计数器：一个文件可以被多个进程打开，文件打开计数器记录该操作，当计数器为0时，可以删除该文件条目。</li>
<li>文件磁盘位置：定位文件在磁盘的位置</li>
<li>访问权限：每个进程用一个访问模式访问文件。<br>系统调用create和delete的操作的是关闭文件而不是打开的文件</li>
</ul>
<h5 id="内部文件结构"><a href="#内部文件结构" class="headerlink" title="内部文件结构"></a>内部文件结构</h5><p>由于磁盘文件总是按块来分配的，所以文件的最后一块的部分空间通常会被浪费。按块分配所浪费的字节称为内部碎片，块越大，内部碎片也越大。</p>
<h4 id="访问方法"><a href="#访问方法" class="headerlink" title="访问方法"></a>访问方法</h4><h5 id="顺序访问"><a href="#顺序访问" class="headerlink" title="顺序访问"></a>顺序访问</h5><p>顺序访问就是打开文件后，一个字节一个字节的读，一个20Kb的文件，必须先读完前10Kb（即使不做任何操作），才能访问到第11Kb。</p>
<p>顺序访问是通过一个指针操作的，指针可以按顺序移动（有的系统允许向前或者向后跳过n个记录），也可以重新设置到开始位置（reset）</p>
<h5 id="直接访问"><a href="#直接访问" class="headerlink" title="直接访问"></a>直接访问</h5><p>直接访问也叫相对访问，其原理是基于磁盘的特性的，磁盘能够随时访问其任意位置。</p>
<p>支持直接访问的文件中，文件由固定长度的逻辑记录组成，通过这种逻辑记录（如每一个块的编号，记录等）能够做到访问文件的任意位置。</p>
<p>直接访问可以立即访问大量信息，所以极为有用</p>
<h4 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h4><p>为了管理数据，需要合理的组织方式</p>
<p>为简单起见，可以将存储文件系统的一大块（手动）分配的空间称为卷，一个卷可以存放多个操作系统。</p>
<p>每个卷包含了系统上文件的信息，保存在设备目录或卷表中。  设备目录记录了卷上所有文件的信息</p>
<h5 id="单层目录结构"><a href="#单层目录结构" class="headerlink" title="单层目录结构"></a>单层目录结构</h5><p><img src="/2021/07/12/osnote-md/Xnip2021-06-04_13-28-02.jpg"><br>在一个目录下存在：</p>
<p>命名问题：文件位于同一个目录下，他们必须具有唯一名称。<br>分组问题</p>
<h5 id="双层目录结构"><a href="#双层目录结构" class="headerlink" title="双层目录结构"></a>双层目录结构</h5><p>对于双层结构目录的结构，每个用户都有自己的用户文件目录(user file directory,UFD)。</p>
<p>因此在每个UFD中所有的文件名称唯一即可，不同的用户可以有相同拥有文件名的问题。</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-04_13-28-57.jpg"></p>
<p>虽然双层结构目录解决了名称冲突问题，但是它仍有缺点。这种解耦股有效地对用户加以隔离。这种隔离在用户需要完全独立时是有点，但是在用户需要在某个任务上进行合作和访问其他文件时却是一个缺点。</p>
<p>为了访问指定的文件唯一，用户必须知道要访问文件的路径名（path name）。也没有解决分组问题</p>
<h5 id="树状目录结构"><a href="#树状目录结构" class="headerlink" title="树状目录结构"></a>树状目录结构</h5><p>树是最常用的目录结构。树有根目录，并且系统内的每一个文件都有唯一路径名。</p>
<p>当前目录：通常情况下，一个进程都有一个当前目录，包含了进程当前感兴趣的绝大多数文件。子进程的当前目录通常是创建子进程的父进程的当前目录。 用户可以使用系统调用重新定义当前目录</p>
<p>路径名：路径名有绝对路径和相对路径两种形式，绝对路径从根路径开始，相对路径从当前目录开始</p>
<p>采用树状目录结构的一个问题是：如何处理删除目录。如果目录为空，那么可以简单的删除条目，如果目录不为空，可以有两个选择：</p>
<p>    强制要求如果目录不为空就无法删除目录。如MS-DOS系统<br>    递归删除目录下的所有子目录和文件。如linux下的rm命令</p>
<p><img src="/2021/07/12/osnote-md/Xnip2021-06-04_13-30-51.jpg"><br>上图表示的是树状目录。树状结构禁止共享文件和目录，因为允许共享文件和目录后，树就变成了图。</p>
<p>无环图是树状目录结构的一个扩展，允许目录含有共享子目录和文件<br><img src="/2021/07/12/osnote-md/Xnip2021-06-04_13-31-58.jpg"></p>
<h3 id="文件系统实现"><a href="#文件系统实现" class="headerlink" title="文件系统实现"></a>文件系统实现</h3><h4 id="文件系统结构"><a href="#文件系统结构" class="headerlink" title="文件系统结构"></a>文件系统结构</h4><p>磁盘提供大量的外存空间来维持文件系统。磁盘的下述两个特点使得其成为存储多个文件的方便介质。</p>
<ul>
<li>可以原地重写；</li>
<li>可以直接访问磁盘上的任意一块信息。</li>
</ul>
<p>为了提供对磁盘的高效且便捷的访问，操作系统通过文件系统来轻松地存储、定位、提取数据。文件系统有两个设计问题。</p>
<ul>
<li>定义文件系统对用户的接口</li>
<li>创建数据结构和算法来将逻辑文件系统映射到物理外存设备上<br>另外，与内存管理的部分方式相同，磁盘同样是以块为单位进行转移的。每块为一个或多个扇区</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/09/computerNet-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/09/computerNet-md/" itemprop="url">计算机网络部分知识点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-07-09T18:40:55+08:00">2021-07-09</time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="第一章计算机网络和因特网"><a href="#第一章计算机网络和因特网" class="headerlink" title="第一章计算机网络和因特网"></a>第一章计算机网络和因特网</h2><p>链路层交换机主要用在接入网中，路由器主要用在网络核心</p>
<p><strong>接入网</strong></p>
<ol>
<li>DSL(Digital Subscribe Line)数字用户线</li>
<li>CIC(Cable Internet Access)电缆因特网接入</li>
<li>FTTH(Fiber TO The Home)光纤到户</li>
<li>以太网和WIFI</li>
<li>广域无线接入</li>
</ol>
<p><strong>物理媒体</strong></p>
<ol>
<li>双绞线</li>
<li>同轴电缆</li>
<li>光纤</li>
<li>陆地无线电信道</li>
<li>卫星无线电信道</li>
</ol>
<p>分组交换常见方式是存储转发机制<br>所谓存储转发是指交换机在收到一个完成的分组，才会向链路输出转发分组，否则就将收到的部分分组缓存起来；因为缓存等待一个分组的全部数据而导致的时间开销被称为存储转发时延<br>如果缓冲区存不下了，就会丢包<br>时延 = 处理时延 + 排队时延 + 传输时延 + 传播时延</p>
<p>实际上，分组交换机之所以能够知道往哪去是因为其内部有一个转发表，这个表维护了一个IP地址和链路的对应关系，所以处理流程为：<br>通过分组的必要信息，获得目的端系统的IP地址<br>通过IP地址索引转发表，从而确定输出链路</p>
<p><strong>电路交换</strong></p>
<ol>
<li>时分复用</li>
<li>频分复用</li>
<li>波分复用</li>
<li>码分复用</li>
</ol>
<p><strong>分组交换的优点：</strong><br>    它提供了比电路交换更好的带宽共享；<br>    它比电路交换更简单、更有效、实现成本更低；</p>
<p><strong>分组交换的缺点：</strong><br>    分组交换不适合实时服务，因为端到端的时延是可变、不可预测的，这和整个网络的情况相关；</p>
<p><strong>电路交换的优点：</strong><br>    提供了端对端传输数据的速率保证；</p>
<p><strong>电路交换的缺点：</strong><br>    电路交换存在静默期，这是指专用电路空闲时，其占用的资源并没有得到充分的利用；<br>    建立连接的过程比较复杂；</p>
<p><strong>吞吐量：</strong> 对于某条路径上的结点来说，和该结点有关的速度有两个：接收数据的速度和发送数据的速度，而该结点的吞吐量是这两个速度中较小的一个；对于某条路径来说，该路径的吞吐量则是所有节点的吞吐量的最小值；</p>
<h2 id="第二章-应用层"><a href="#第二章-应用层" class="headerlink" title="第二章 应用层"></a>第二章 应用层</h2><p>HTTP被称为无状态协议<br>在因特网应用程序中，客户端和服务器将在很长的时间范围里通信；应用程序将根据自身的特点，选择以规则的间隔周期性性发出请求也可以间断性一个个发出请求。当通信是使用TCP协议时，服务器端需要做出一个决定：这些请求是使用一个TCP连接完成还是通过独立的TCP连接完成。如果采取前一个方法，则称应用程序使用持续连接，如果使用后一种方式，则称为非持续连接。</p>
<p>使用非持续连接时，每个TCP连接在服务器发送一个对象后就会关闭，也就是每个TCP只传送一个请求报文和响应报文；</p>
<p>为了描述持续连接和非持续连接的特点，我们引入RTT(Round-Trip Time)。RTT指的是，一个短分组从客户端到服务器，然后再返回客户端所用的时间。RTT包括分组的传播时延、排队时延、处理时延（因为是短分组，所以其传输时延可不计）；因为客户端和服务器建立TCP连接的时候，会通过一个三次握手的过程来交换传输控制信息。三次握手的前两次占用了一个RTT，客户结合第三次握手通行会通过该连接发送一个HTTP请求报文，一旦该分组到达服务器，服务器便开始使用TCP传输HTML对象。因此，粗略地说，响应时间是两个RTT加上传输HTML的时间（不是传播）。</p>
<p><strong>非持续连接</strong>必须为每个请求新建一个TCP连接，而每个TCP连接将占用系统资源，包括缓冲区和变量等，这样服务器的负担就很重了。第二，一个对象将通过两个RTT的时延才能交付。</p>
<p>如果使用<strong>持续连接</strong>，那么服务器在发送响应报文后将保持该TCP打开，后续客户端可以使用该连接来向服务器发出请求。不但一个完整的页面可以通过同一个连接传送，同一台服务器上的多个页面也可以通过同一个连接发送。这就提高了效率；</p>
<p>一般来说，如果一条连接在一定的时间间隔后没被使用的话，就会被关闭。HTTP默认使用的是带流水线的持续连接。</p>
<h4 id="请求报文"><a href="#请求报文" class="headerlink" title="请求报文"></a>请求报文</h4><p>一个请求报文具有至少一行的内容。请求报文的第一行称为请求行，其后继的各行被称为首部行。请求行包含三个内容：方法字段、URL字段、HTTP版本；其中方法字段可为：GET、POST、PUT、DELETE、HEAD等。URL字段里可以传递请求对象的标志；</p>
<p>首部行包含是否在发送完响应报文后关闭TCP连接的Connection；请求的主机地址（该头部信息被Web高速缓存所要求）；浏览器版本；可接受的语言等头部信息；</p>
<p>在首部行之后一个空行，之后便是请求的“实体体”。该实体体可以在POST方法里传递Form表单内容或者传递其它一些二进制流数据等。值得注意的是，表单也不一定必须使用POST方法。如果使用get,实体体为空，会显示在url中。</p>
<p>Head类似于get方法，将会用一个http报文进行响应，但是不返回请求对象，经常用作调试跟踪。put方法允许用户上传对象到指定的Web服务器上指定的路径。Delete方法允许用户或应用程序删除Web服务器上的对象。</p>
<h4 id="响应报文"><a href="#响应报文" class="headerlink" title="响应报文"></a>响应报文</h4><p>响应报文总体上也分三个部分，第一部分是状态行，包含HTTP版本、状态以及状态信息等内容；第二部分是首部行，包含发送日期、服务器类型、上一次修改请求资源的时间、内容的类型等内容。第三部分是实体体。实体体包含请求对象本身。</p>
<p>这里的Date是从文件系统中检索到该对象，插入到响应报文，并发送该响应报文的时间。</p>
<p>常见状态码</p>
<ul>
<li>200：请求成功 处理方式：获得响应的内容，进行处理</li>
<li>301：请求到的资源都会分配一个永久的URL，这样就可以在将来通过该URL来访问此资源 处理方式：重定向到分配的URL</li>
<li>400：非法请求 处理方式：丢弃</li>
<li>404：没有找到 处理方式：丢弃</li>
<li>505：服务器不支持请求报文使用的http版本。</li>
</ul>
<h4 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h4><p>前面提到，HTTP是无状态协议，但是Web站点为了识别用户身份或者限制用户访问的时间或者将用户访问的内容同用户身份相关联，Web站点可以使用Cookie技术；</p>
<p>Cookie技术包含4个组件<br>    HTTP响应报文里增加一个关于Cookie的首部行；<br>    HTTP请求报文里增加一个关于Cookie的首部行；<br>    用户端系统保留一个Cookie文件，由浏览器保存维护；<br>    Web站点建立Cookie和用户身份的关联；</p>
<h4 id="web缓存"><a href="#web缓存" class="headerlink" title="web缓存"></a>web缓存</h4><p>Web缓存器也被称为代理服务器，它代表初始web服务器来满足HTTP请求。它有自己的存储空间，并在存储空间里保持有最近请求过的对象的副本；可以通过配置浏览器，将所有指向初始服务器的请求首先指向代理服务器。</p>
<p>当代理服务器收到一个HTTP请求后，它将检查本地是否缓存过该对象，如果缓存过该对象，将检查是否过期，如果没有过期，则直接将该对象返回给浏览器；如果本地不存在或者存在已过期，则代理服务器将根据请求报文里的Host首部行以及请求行里的URL字段向初始服务器发出请求，然后将响应对象返回给浏览器并缓存在本地。</p>
<h4 id="FTP"><a href="#FTP" class="headerlink" title="FTP"></a>FTP</h4><p>HTTP和FTP都是应用层协议，它们都运行在TCP协议之上，但是它们之间也有一些重要区别，其中一个就是FTP使用连个并行的TCP连接来传输数据，一个TCP被称为控制连接，用来传输FTP命令；一个TCP连接被称为数据连接，用于传输文件数据；因为FTP协议内，控制信息是通过一个独立的TCP连接传输，所以我们称FTP的控制信息是带外传送的；如果控制信息和数据信息通过同一个TCP传输，则称为带内传送。TCP控制连接端口21，数据连接端口20</p>
<p>需要注意的是，FTP中控制连接贯穿整个会话，但是数据连接会在一个文件开始传输的时候建立，在传输结束后关闭；所以每次传输一个新的文件时，都会新建一个数据连接；</p>
<p>同时，FTP需要在整个会话期间，保留用户的状态，也就是将控制连接同用户账户关联起来，同时记录用户在远程目录树上的操作，这就限制了FTP可以同时维持的会话总数.</p>
<h4 id="SMTP"><a href="#SMTP" class="headerlink" title="SMTP"></a>SMTP</h4><p>因特网电子邮件系统有三个核心组件：用户代理、邮件服务器、SMTP（简单邮件传输协议，Simple Mail Transfer Protocol）。</p>
<p>邮件服务器构成了电子邮件系统的核心。每个收发方在邮件服务器上拥有一个邮箱；一个典型的电子邮件发送过成为：发送方通过用户代理将邮件传送到发送方的邮件服务器，然后再传输到接收方的邮件服务器，然后邮件被分发到接收方的邮箱里；接收方从邮件服务器里获取自己的邮件时需要通过邮件服务器的验证</p>
<p>SMTP是因特网中电子邮件的主要应用层协议，它使用TCP可靠数据传输从发送方的邮件服务器向接收方的邮件服务器发送邮件；在每台邮件服务器上同时运行SMTP服务器和SMTP客户端。当邮件服务器接收其他邮件服务器的邮件时，它表现为SMTP服务器，当邮件服务器向其他邮件服务器发送邮件时，表现为SMTP客户端。</p>
<p>如果发送端不能将邮件发送个接受端的服务器，发送端的邮件服务器会在一个报文队列中保持该报文并在以后尝试再次发送。</p>
<p>传输的三个阶段：握手、传输、关闭连接。</p>
<p>SMTP25号端口。SMTP是持续连接的。对每一报文，客户使用一个新的MAIL FROM：crepes.fr开始。当所有报文发送完后才发送QUIT，断开连接。SMTP出现在因特网之前，尽管它有着很不错的特性，但是它具有的某种陈旧的特征表明它仍然是一种继承的技术，比如，它限制邮件报文的所有部分只能使用7比特的ASCII表示，这就导致二进制多媒体文件需要编码为ASCII，而且在发送方需要编码，接收方则需要解码。</p>
<p>值得注意的是，SMTP报文一般不使用中间邮件服务器发送报文，也就是邮件不会在中间某个邮件服务器保留；在SMTP握手阶段，SMTP客户端将介绍发送方和接收方的邮箱地址；一旦介绍完毕后，SMTP客户端将开始发送报文</p>
<p>HTTP和SMTP都是用TCP协议；持续的HTTP和SMTP都是用持续连接；但是两者也有区别。</p>
<ol>
<li>首先HTTP被设计为一个Pull协议而SMTP被设计为一个Push协议。即用户通过HTTP主动向服务器请求内容，而SMTP则是客户将内容推向服务器端；</li>
<li>第二个区别就是HTTP传输的数据不一定是用ASCII字符，但是SMTP则只能使用ASCII字符；</li>
<li>第三个重要区别就是，HTTP将每个对象封装在自己的响应报文里，而SMTP则将所有的报文对象放到一个报文之中；</li>
</ol>
<h4 id="POP3-IMAP-HTTP"><a href="#POP3-IMAP-HTTP" class="headerlink" title="POP3 IMAP HTTP"></a>POP3 IMAP HTTP</h4><p>需要注意的是，SMTP是邮件服务器之间发送邮件报文的协议，并不是用户通过代理和邮件服务器之间通信的协议；用户代理使用邮件访问协议来从邮件服务器上获取邮件信息；目前常用的邮件访问协议有POP3（Post Office Protocol-Version 3）、因特网邮件访问协议（IMAP，Internet Mail Access protocol）和HTTP</p>
<h4 id="POP3"><a href="#POP3" class="headerlink" title="POP3"></a>POP3</h4><p>POP3是一个非常简单的协议，因为简单，所以功能有限；POP3使用端口110来建立TCP连接（SMTP使用端口25）；POP3按照三个阶段进行工作：特许、事务处理和更新；在特许阶段，用户代理发送密码和用户名，进行身份鉴别；第二阶段，用户代理取回报文，同时还可以做删除、取消删除等标记或者统计邮件信息；第三个阶段是在用户退出后，POP3结束会话，删除被标记的邮件；</p>
<p>一个需要注意的是，POP3用户代理可以使用两种事务处理模式：一种是下载并删除，另一种是下载保留；POP3代理发出的命令和其工作模式相关；下载并删除的方法存在的问题是，如果用户在一台设备上查看了邮件（下载了邮件）后，邮件将被删除，那么在其他设备上将无法查看邮件；这给用户带来一定的不便。使用下载保存方式，则用户下载邮件后，邮件还在服务器上。</p>
<p>在用户代理与邮箱服务器之间的POP3会话期间，该POP3服务器保留了一些状态信息，特别是标记了哪些用户报文被标记为删除了。但是POP3服务器并不在POP3绘画过程中携带状态信息，大大简化了POP3的服务。</p>
<h4 id="IMAP"><a href="#IMAP" class="headerlink" title="IMAP"></a>IMAP</h4><p>POP3协议无法为用户提供邮件分类管理的功能，虽然用户可以通过将邮件下载到本地，然后由用户代理程序做分类管理，但是处理的结果是无法同步到其他查看设备上的。为了解决这一问题，IMAP诞生了。IMAP是一个邮件访问协议，比POP3要复杂的多，当然也就有更多的特色了。</p>
<p>（远程）IMAP将每一份邮件和一个一个文件夹联系起来，当报文第一次到达服务器时，它与收件人的INBOX相关联。收件人可以将邮件移到新创建的文件夹，阅读邮件，删除邮件等。IMAP允许用户在不同文件夹里移动邮件并且查询邮件。值得注意的是，IMAP服务器维护了IMAP会话的用户状态信息，但是POP3并不；IMAP协议还允许用户代理获取报文组件而不是报文整体。</p>
<h4 id="基于Web的电子邮件"><a href="#基于Web的电子邮件" class="headerlink" title="基于Web的电子邮件"></a>基于Web的电子邮件</h4><p>这种方式主要是指，用户使用HTTP协议和邮件服务器通信。用户代理就是普通的浏览器，但是，邮件服务器之间还是使用SMTP协议的</p>
<h4 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h4><p>首先，需要注意的是，在计算机网络里，我们通过IP地址来标记某一时刻网络中唯一的主机。IP地址（IPV4）由4个字节组成，有着严格的层次结果.但是，同时也就引入一个问题：主机名和IP地址的转换问题；</p>
<p>计算机网络里有一种应用专门提供这样的服务，它就是DNS（Domain Name System）域名系统。DNS是一个由分层的DNS服务器组成的分布式数据库和一个使得主机可以查询分布式数据库的应用层协议组成；</p>
<p>DNS运行在UDP之上，使用53号端口</p>
<p>除了提供主机名到IP地址的转换外，DNS还提供以下重要服务：</p>
<ul>
<li>主机别名</li>
<li>邮件服务器别名</li>
<li>负载分配</li>
</ul>
<p><strong>存在三种DNS服务器：根DNS服务器、顶级域DNS服务器和权威DNS服务器；</strong><br>举例说明，其工作的普遍流程：一个DNS客户端，希望获得<a target="_blank" rel="noopener" href="http://www.baidu.com的ip地址,粗略的说,dns客户端首先和根dns服务器取得联系,它将返回负责解析顶级域名com的服务器的ip地址(或者其集合),客户将同这些服务器之一取得联系,然后顶级域dns服务器建返回baidu.com的权威服务器的ip集合,客户端通过与这些服务器之一取得联系,获得www.baidu.com的ip地址./">www.baidu.com的IP地址，粗略的说，DNS客户端首先和根DNS服务器取得联系，它将返回负责解析顶级域名com的服务器的IP地址（或者其集合），客户将同这些服务器之一取得联系，然后顶级域DNS服务器建返回baidu.com的权威服务器的IP集合，客户端通过与这些服务器之一取得联系，获得www.baidu.com的IP地址。</a></p>
<p>DNS查询有两种，<strong>一种是递归查询一种是迭代查询</strong>；实践中，查询通常满足这样的模式：从请求主机到本地DNS服务器的查询是递归的，其余查询是迭代的。所谓迭代就是，如果请求的接收者不知道所请求的内容，那么接收者将扮演请求者，发出有关请求，直到获得所需要的内容，然后将内容返回给最初的请求者。也就是说，在递归查询中，一定要给请求者想要的答案；迭代查询则是指，如果接收者没有请求者所需要的准确内容，接收者将告诉请求者，如何去获得，但是自己并不去发出请求。</p>
<p>DNS本地缓存：。。。</p>
<h4 id="P2P"><a href="#P2P" class="headerlink" title="P2P"></a>P2P</h4><p>BitTorrent 是一种用于文件分发的流行P2P协议；用BitTorrent的术语来说，参与一个特定文件分发的所有对等方的集合被称为一个洪流；在一个洪流中的对等方彼此下载等长度的文件块；当一个对等方下载文件块的时候，也向其他对等方发送了多个块；一旦某对等方获得了完整文件，就可以自私地离开洪流或者大公无私地留下来继续向其他对等方发送文件.</p>
<h3 id="第三章-传输层"><a href="#第三章-传输层" class="headerlink" title="第三章 传输层"></a>第三章 传输层</h3><p>UDP（用户数据报协议）它提供一种不可靠、无连接的服务；另一种是TCP，它提供可靠的，面向连接的服务；运输层分组也被称为报文段；</p>
<p>UDP有以下好处：</p>
<ol>
<li>关于何时、发送什么数据的应用层控制更为精细：这是因为一旦应用程序将数据交给UDP，UDP就会打包将其发送给网络层，不会受到传输层的调节，这在一些实时应用中比较实用；当然，应用程序还可以通过UDP+自主开发一些功能的模式来扩展UDP。</li>
<li>无需建立连接：所以就不会引入额外的时延。这也可能是DNS使用UDP而不是TCP的主要原因，如果使用TCP的话，DNS服务将会慢很多；HTTP使用TCP的主要原因是对TCP的可靠性的依赖超过对速度的要求；</li>
<li>无需维护连接状态：TCP为了实现可靠数据传输和拥塞控制需要在端系统中维护一些参数，这些参数包括：接收和发送的缓存、拥塞控制参数、确认号和序号；这些参数信息都是必须的；而UDP因为不建立连接，所以自然也就不需要维护这些状态，这就减少了时空开销；</li>
<li>分组首部更小：TCP有20字节的首部开销，而UDP只有8字节；</li>
</ol>
<p>这些应用程序使用了TCP作为其传输层协议：电子邮件、远程终端访问、Web、文件传输；这些应用通常使用UDP作为其传输层协议：远程文件服务器、网络管理（因为这里应用即便在网络处于拥塞的情况下仍要工作，所以UDP更为合适）、路由选择协议和名称转换（DNS）；这些应用两个都有使用：流式多媒体、因特网电话等多媒体应用；这些应用对实时性的要求较高同时对可靠性的要求又不是很高，所以既可以使用UDP也可以使用TCP协议。</p>
<p>UDP首部只有4个字段，每个字段占用两个字节，分别是：源端口号、目的端口号、长度和校验和；其中，长度表示包含首部在内的UDP报文段长度，以字节为单位；校验和字段用来计算报文段在传输的过程中是否出现了差错</p>
<h3 id="面向连接原理"><a href="#面向连接原理" class="headerlink" title="面向连接原理"></a>面向连接原理</h3><p>TCP提供全双工服务，并且是点对点的；TCP协议无法提供“多播”服务，一条TCP连接只关联一个发送方和接收方（当然，发送方也是接收方）；<br><strong>三次握手，前两次报文段不承载“有效负载”，第三次握手的时候，报文段是可以装载“有效负载”的</strong><br>TCP报文段结构，从整体上来说由首部+数据字段组成；其中数据字段来自应用层，其长度不能大于MSS；首部的常规长度为20字节，但是值得注意的是，TCP首部是可变长的；TCP首部是以32比特为单位组织的</p>
<p>一条TCP连接可以采取任意数字作为初始序号，这样可以减少将那些残存在网络中的报文段误认为是新建连接的报文段（新旧连接恰巧采用了相同端口）</p>
<p>一个报文段的序号就是该报文段数据字段首字节的序号；确认号就是接受主机正在等待接收的数据的下一个字节序号；值得注意的是，服务端对接收端发来的报文段的确认被装载到一个从服务端发往到接收端的报文段中，这种确认被称为“捎带”</p>
<h3 id="可靠原理"><a href="#可靠原理" class="headerlink" title="可靠原理"></a>可靠原理</h3><blockquote>
<p>一个可靠数据传输协议，将要面对以下问题：分组丢失、分组损坏到达、分组乱序到达</p>
</blockquote>
<blockquote>
<p>总结可靠传输需要的技术：检验和、序号、定时器、肯定和否定确认分组。</p>
</blockquote>
<ul>
<li>经完全可靠信道的可靠数据传输：rdt 1.0</li>
<li>经具有比特差错信道的可靠数据传输：rdt 2.0</li>
<li>rdt 2.0 中有一个致命的缺陷，就是没有考虑到 ACK 和 NAK 分组受损的可能性。<br>  考虑ACK和NAK受损的个两可能性：<br>  增加足够的校验和比特<br>  当接受到模糊不清的ACK和NAK分组时，只需要重传当前数据分组。这引入了冗余分组</li>
<li>rdt 2.2 是在有比特差错信道上实现的一个无NAK的可靠数据传输协议。<br>  rdt 2.1和rdt 2.2的区别在于，接收方此时必须包括由一个ACK报文所确认的分组序号</li>
<li>经具有比特差错的丢包信道的可靠数据传输：rdt3.0</li>
</ul>
<p>rdt 3.0 是一个功能正确的协议，但是由于它是一个停等协议，大部分的时间都浪费在等待确认上面，所以性能不好。<br>解决这种特殊性能问题的一个简单的方法是：不使用停等方式运行，允许发送方发送多个分组而无需等待确认。这种技术被称为 流水线。</p>
<p>要使用流水线技术，则须：</p>
<ul>
<li>增加序号范围。因为要传送多个分组，而每个传输中的分组必须有一个单独的序号。</li>
<li>协议的发送方和接收方两端必须能缓存多个分组。发送方至少得能缓存那些已发送但未确认的分组，而接收方或许也需要缓存那些已经正确接收的分组。</li>
<li>所需序号的范围和对缓冲的要求取决于数据传输协议如何处理丢失、损坏及延时过大的分组。</li>
</ul>
<p>流水线的差错恢复有两种基本方法：</p>
<ul>
<li>回退 N 步</li>
<li>选择重传</li>
</ul>
<h4 id="回退N步"><a href="#回退N步" class="headerlink" title="回退N步"></a>回退N步</h4><p>全部序号就被划分为0-base-1，这一部分的分组是已发送且收到接收方确认的分组，base<del>next-1这一部分的分组是已发送但是尚未收到确认的，其中base是尚未收到确认的最小序号；next-1</del>base+N-1表示当前发送方可以使用的序号，表示一种发送能力；当发送方收到确认号为base的确认分组后就会向前移动窗口，所以回退N步也被称为滑动窗口协议</p>
<ul>
<li>上层调用：检查next Sequence是否在窗口之内，如果在，这说明发送方还有发送能力，发送之；</li>
<li>收到ACK：回退N步策略对序号为n的分组采取累积确认的方式，即当收到序号为n的ACK时，表明序号小于等于n的分组全部到位；发送方收到的ACK毕竟来自接收方，收到ACK的情况还得看接收方如何发送；</li>
<li>超时事件：如果发生超时事件，那么发送方会重发所有已发送但是未确认的分组，即分组号在base和next sequence-1之间的所有分组；这也是为什么叫“回退N步”，如果收到一个ACK，则定时器会重行启动；如果没有待确认的分组，定时器将被终止；</li>
</ul>
<h4 id="选择重传"><a href="#选择重传" class="headerlink" title="选择重传"></a>选择重传</h4><p>接收方将确认一个正确接收的分组而不管其是否按序；失序的分组被缓存，直到形成连续数据后将其提交给上层；值得注意的是，如果接收方收到了已经确认的分组，则说明确认ACK丢失，或者时延太长，接收方和发送方沟通不及时；这也表明了关于那些分组到位了，那些分组还没到位，接收方和发送方有着不一样的视图。</p>
<p>另外还需要注意的是，序号的重用问题，如果在分组中序号字段的位数为k，那么最大的序号为2^k-1，所以有可能不同分组同时占用一个序号，为了避免这种情况，需要做的是控制分组的生命周期。窗口长度必须小于或等于序号空间大小的一半。</p>
<h4 id="往返时间的估计与超时"><a href="#往返时间的估计与超时" class="headerlink" title="往返时间的估计与超时"></a>往返时间的估计与超时</h4><p>TCP一般来说通过Estimated RTT=(1-a)Estimated RTT+a*Sample RTT来计算因路由器的拥塞和端系统负载变化所导致变化的RTT。a一般取1/8；因为Estimated RTT表示最近的网络状况，所以其理应得到较大的权值；这种方法也被称为指数加权移动平均</p>
<p>除了估计RTT外，计算RTT的变化也是ok的，DevRTT =(1-b)DevRTT+b*|Sample RTT-Estimated RTT|；其中b的推荐值为0.25；当Sample RTT变化较大的时候，DevRTT的值较大，当Sample RTT变化较小的时候，DevRTT就较小；</p>
<p>TCP是如何考虑超时时间的呢？该时间因略大于测量的RTT，不易过小——容易引起不必要的重传，也不易过大——网络对于报文段丢失情况的反应就会变慢；最后TCP采用了如下计算方式：Timeout Interval=Estimated RTT+4*Dev RTT；</p>
<h4 id="超时与重传"><a href="#超时与重传" class="headerlink" title="超时与重传"></a>超时与重传</h4><p>TCP使用超时重传和冗余确认技术来处理超时、丢失等情况；使用确认、序号等技术来保证按序到达；使用校验和来检验是否报文段在传输过程中是否发生了错误；</p>
<h4 id="超时时间加倍"><a href="#超时时间加倍" class="headerlink" title="超时时间加倍"></a>超时时间加倍</h4><p>在大多数TCP实现中，当发生超时事件时，超时时间并不是从Estimated RTT和Dev RTT推算出来而是直接将超时时间设置为原来的两倍；然而，每当定时器在另两个事件（收到ACK和接收到上层应用数据）发生时，新的超时时间将由上面提到的两个值计算出来；实际上，这是一种形式受限的拥塞控制</p>
<h4 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h4><p>接收方接收到某个报文段时，会检查该报文段是否是按序到达，如果不是，那么接收端会发送对已经收到的最后一个连续报文段的确认，所以如果发送方收到冗余ACK，说明有多个报文段到达了接收端，但不是接收端所期望的——这意味着，很有可能发生了丢失。所以发送方可以在定时器过时之前快速重传所丢失的报文段</p>
<h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><p>流量控制是一个速度匹配服务：TCP连接的发送方和接收方都各自维护一个缓存，因此两者的数据交换应该在一个合理的速度范围内：不让对方发生数据溢出；TCP为它的应用程序提供了这种服务：流量控制服务。虽然流量控制和拥塞控制所采取的动作非常相似，但是它们的目的很明显并不同。</p>
<p>在TCP首部中有一个窗口大小字段，TCP连接的双方通过该字段来向对方表明自己的窗口大小，即缓存空间的大小；同样，在TCP连接的两端，各自维护着相关的变量：last Sent、last Acked；在发送方，这两个变量之间的分组就是已经发送但是尚未确认的分组；而在接收方，last Read表示应用进程下一次读取的数据，last Revd表示最后纳入缓存的报文段编号（注意，我们讨论的前提是TCP会将失序到达的报文段丢弃哦~）；通过这些变量以及报文段首部中窗口大小字段，我们就可以对发送速度做一些控制：在发送方last Sent-last Acked应该小于等于接收方的窗口大小；在接收端A=last Received-last Read就是已经使用的空间大小，所以窗口大小=buffer-A；</p>
<p>如果接收方的窗口大小为0，那么发送端该如何处理呢？接收方在没有ACK或者数据要向发送端发送时，不会通知发送方他的窗口大小已经改变。也就是说，如果应用程序读取了缓存中的数据，发送方是不会知道的，除非它向接收方发送了数据；当接收到窗口大小为0的报文段后，发送方会向接收方间隔发送只有一个字节的数据。</p>
<h3 id="拥塞控制原理"><a href="#拥塞控制原理" class="headerlink" title="拥塞控制原理"></a>拥塞控制原理</h3><p>计算机网络拥塞的原因是因为网络中的分组太多，而链路带宽和路由器缓存容量都是有限的；</p>
<ol>
<li>当分组的到达速率接近链路容量时，分组将经历巨大的排队时延；</li>
<li>发送方必须执行重传，为缓存溢出而丢弃的分组</li>
<li>发送方进行的不必要重传会引起路由器转发不必要的分组副本。</li>
<li>当一个分组沿着一条路径被丢弃时，每个上游路由器的资源被浪费掉了</li>
</ol>
<p><strong>拥塞控制：拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；</strong><br><strong>流量控制：流量控制是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收。</strong></p>
<p>依据网络层是否提供显式支持，将拥塞控制分为：<strong>端到端拥塞控制、网络辅助拥塞控制</strong><br>TCP必须使用端到端的拥塞控制而不是网络辅助的拥塞控制，因为IP并不会向端系统提供显式的网络拥塞反馈；<br>TCP所采用的方法是让每一个发送方根据其所感知的网络拥塞程度来限制其能向连接发送流量的速率；如果TCP判断网络通畅，那么它会提高发送速率，如果TCP判断网络拥塞，那么它会限制发送速率；需要解决三个问题：</p>
<ol>
<li>TCP如何限制发送速率？</li>
<li>TCP如何感知网络拥塞程度？</li>
<li>TCP该以何种算法改变其发送速率？</li>
</ol>
<p>我们将TCP发送方的丢包事件定义为：要么超时，要么收到接收方的3个冗余ACK；如果网路拥塞，那么网络中的路由器就会发生缓存溢出，进而导致数据报被丢弃，然后就会引起发送方的丢包事件；此时，TCP发送方就可以认为TCP连接出现了拥塞<br>另外，TCP将接收方发送的ACK视为网络通畅的标志，如果ACK到达的速率较高，那么TCP的拥塞窗口就会以较高的速率扩大，如果ACK到达的速率较慢，那么TCP拥塞窗口的增加速度也会较慢；因为TCP使用ACK对拥塞窗口做出调节，所以也别称为自计时的；<br>一个丢失的报文段意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率；<br>    一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当收到对先前报文段的确认时，可以增加发送方的速率；<br>    带宽检测；TCP调节器传输速率的策略是增加其速率以响应到达的ACK，除非出现丢包，此时才减少发送速率；以为网络中没有明确的拥塞控制状态信令，ACK和丢包事件充当了隐式信号.</p>
<p>tcp拥塞算法主要包含三个部分：<strong>慢启动、拥塞避免、快速恢复</strong></p>
<p>TCP连接在开始的时候，其cwnd常设置为一个MSS，然后在慢启动状态每收到一个ACK，cwnd就增加一个MSS；这样的话，在慢启动阶段，发送速率是指数增加的（1,2,4,8…）<br>在慢启动阶段，如果发生了超时事件，那么ssthresh就被设置为当前cwnd的一半，然后将cwnd置为1；当cwnd逐步增加到ssthresh时，再翻倍增加cwnd就有一点鲁莽了，所以此时TCP结束慢启动，进入拥塞避免模式。在拥塞避免模式里，TCP将更谨慎地增加cwnd；如果收到冗余ACK，那么TCP会做一次快速重传，然后进入快速恢复阶段；</p>
<h4 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h4><p>指数增长。这里慢启动指的起点低，而不是增长慢</p>
<h4 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h4><p>将cwnd减半，然后线性增长</p>
<h4 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h4><p>在快速恢复阶段，对于引起TCP进入该状态的缺失报文段，每收到一个ACK，cwnd增加一个MSS<br>当对丢失报文段的一个ACK到达时，TCP降低cwnd后进入拥塞避免状态；如果出现超时事件，快速恢复在执行如同慢启动和拥塞避免中相同动作后，进入慢启动状态.</p>
<h3 id="第四章-网络层"><a href="#第四章-网络层" class="headerlink" title="第四章 网络层"></a>第四章 网络层</h3><p>网络层的作用：将分组从一台发送主机移动到一台接收主机。需要两种功能：<br>        转发：当一个分组到达路由器的一条输入链路时，路由器必须将该分组移动到适当的输出链路<br>        路由选择：分组从发送方流向接收方时，网络层必须决定这些分组采用的路由或路径，路由选择算法<br>每台路由器都有一张转发表</p>
<p>因特网的网络层IP协议提供单一服务，尽力而为服务，无带宽保证，无丢包保证，无顺序保证，不定时，无拥塞指示。</p>
<p>仅在网络层提供连接服务的计算机网络成为虚电路；仅在网络层提供无连接服务的计算机网络称为数据报网络。</p>
<h4 id="路由器的组成"><a href="#路由器的组成" class="headerlink" title="路由器的组成"></a>路由器的组成</h4><p>路由器的组成部分</p>
<ul>
<li>输入端口：<br>  执行将一条输入的物理链路与路由器相连接的物理层功能<br>  执行与位于入链路远端的数据链路层交互的数据链路层功能<br>  查找功能，查询转发表决定路由器的输出端口，将分组转发到输出端口</li>
<li>交换结构<br>  将路由器的输入端口与输出端口相连<br>  分组通过交换结构转发到输出端口</li>
<li>输出端口<br>  存储从交换结构接收的分组，执行必要的链路层和物理层功能在输入链路上传输这些分组。<br>  当链路是双向的时，输出端口与输入端口在同一线路卡成对出现</li>
<li>路由选择处理器<br>  执行路由选择协议<br>  维护路由选择表、连接的链路状态信息，为路由器计算转发表</li>
<li>路由转发平面<br>  一台路由器的输入端口、输出端口和交换结构共同实现了转发功能，并且用硬件实现（软件太慢，需以纳秒时间尺度运行）</li>
<li>路由控制平面<br>  路由器的控制功能（执行路由选择协议、对上线或者下线链路进行响应、管理功能），在毫秒时间尺度上运行，用软件实现并在选择处理器上执行（一种cpu）</li>
</ul>
<p>网络层三个组件</p>
<pre><code>IP协议
路由选择协议
控制报文协议（ICMP）：报告数据报中的差错、对某些网络层信息请求进行响应的设施
</code></pre>
<h4 id="Ip地址"><a href="#Ip地址" class="headerlink" title="Ip地址"></a>Ip地址</h4><p>a b c 类地址</p>
<ol>
<li><p>获取一块地址<br> 子网获取IP地址：由ISP从它大块地址中分配<br> ISP获取IP地址：IP地址由因特网名字和编号分配机构ICANN管理（也管理DNS根服务器、AS标识号）。ICANN向区域性因特网注册机构分配地址，处理本地域内的地址分配/管理</p>
</li>
<li><p>获取主机地址<br> 组织获得一块地址，就可为组织内的主机、路由器接口逐个分配IP地址<br> 主机地址能手动配置，也能自动配置，即动态主机配置协议DHCP</p>
</li>
<li><p>动态主机配置协议DHCP—UDP<br> DHCP允许主机自动获取一个IP地址<br> DHCP可配置，可以使主机每次连网获得相同IP地址，也可每次分配一个临时IP地址。<br> DHCP还允许主机查看子网掩码、默认网关（第一跳路由器地址）、本地DNS服务器地址<br> DHCP能将主机连接进一个网络的自动能力，常被称为即插即用协议<br> DHCP是一个客户-服务器协议。新来的主机要获得自使用的IP地址等网络配置信息<br> 每个子网都有一台DHCP服务器<br> 若子网没有DHCP服务器，则由一个路由器做DHCP中继代理，该代理知道该网络的DHCP服务器地址</p>
<h4 id="DHCP"><a href="#DHCP" class="headerlink" title="DHCP"></a>DHCP</h4><p>新主机到来时，DHCP协议的四个步骤</p>
</li>
<li><p>DHCP服务器发现<br> 新到的客户通过广播DHCP发现报文，发现一个要与其交互的DHCP服务器<br> 客户在UDP分组中向端口67发送该发现报文，此时必须用广播地址255.255.255.255，源地址是0.0.0.0</p>
</li>
<li><p>DHCP服务器提供<br> DHCP收到DHCP发现报文后，响应一个DHCP提供报文，仍然使用广播地址，因为此时新客户并没有IP地址<br> 可能有多台DHCP服务器，每台服务器提供的报文中，有向客户主机推荐的IP地址、网络掩码以及IP地址租用期（一般几天或几小时）</p>
</li>
<li><p>DHCP请求<br> 客户从提供中选一个，向选中的服务器提供一个DHCP请求报文进行响应，回显配置参数</p>
</li>
<li><p>DHCP ACK<br> 收到DHCP请求报文后，用DHCP ACK报文对其记性响应，证实所传参数<br> 客户收到ACK后，交互完成，在租期内使用DHCP分配的IP地址。DHCP提供了机制允许客户更新对一个IP地址的租用</p>
</li>
</ol>
<h4 id="NAT"><a href="#NAT" class="headerlink" title="NAT"></a>NAT</h4><p>NAT路由器对外界来看像一个具有单一IP地址的单一设备。例如，家里有一个NAT使能路由器，其IP地址138.76.29.7，且进入和离开家庭的报文都有同样的该地址<br>NAT路由器对外隐藏了家庭网络的细节<br>NAT路由器从ISP的DHCP服务器得到它的地址，并且路由器运行一个DHCP服务器，为位于NAT-DHCP路由器控制的家庭网络地址空间中的主机提供地址</p>
<h4 id="ICMP"><a href="#ICMP" class="headerlink" title="ICMP"></a>ICMP</h4><p>CMP被主机和路由器用来沟通网络层信息，如差错报告<br>如『目的网络不可到达』这种错误是在ICMP产生的，IP路由器找不到路径通往指定主机，该路由器就向发送主机发出ICMP报文指示错误<br>ICMP通常被认为是IP的一部分，但从体系结构上来讲它是位于IP之上的，因为ICMP报文是承载在IP分组中的。也就是说，ICMP报文是作为IP有效载荷承载的。</p>
<h3 id="路由选择算法"><a href="#路由选择算法" class="headerlink" title="路由选择算法"></a>路由选择算法</h3><ol>
<li><p>第一种分类方法：</p>
<ul>
<li><strong>全局式路由选择算法</strong><br>  用完整、全局性的网络信息计算出最短路径（最低费用路径）<br>  practically具有全局状态信息的算法称作链路状态算法（LS）</li>
<li><strong>分散式路由选择算法</strong><br>  迭代、分布式的方式计算最短路径<br>  没有结点拥有关于网络链路的完整信息，每个结点仅有与其直接相连链路的信息即可工作<br>  通过迭代计算并与相邻结点交换信息，逐渐计算出最低费用路径，距离向量算法（DV）</li>
</ul>
</li>
<li><p>第二种分类方法：</p>
<ul>
<li><strong>静态路由选择算法</strong><br>  变化缓慢，通常人工干预</li>
<li><strong>动态路由选择算法</strong><br>  网络流量负载或拓扑发生变化时改变路由选择路径<br>  周期性运行或直接响应变化<br>  也容易受路由选择循环、路由震荡等问题的影响</li>
</ul>
</li>
<li><p>第三种分类方法：</p>
<ul>
<li><strong>负载敏感算法</strong><br>  链路费用动态变化来反映链路拥塞水平</li>
<li><strong>负载迟钝算法</strong><br>  链路费用与拥塞无关，当今因特网路由选择算法基本都是迟钝的</li>
</ul>
</li>
</ol>
<h4 id="链路状态路由选择算法LS"><a href="#链路状态路由选择算法LS" class="headerlink" title="链路状态路由选择算法LS"></a>链路状态路由选择算法LS</h4><p>网络拓扑和所有链路费用已知。实践中是由每个节点向网络其他所有节点广播链路状态分组完成的，例如OSPF路由选择协议由链，路状态广播算法完成<br>所有节点都具有该网络的信息，每个节点运行LS算法<br>Dijkstra算法<br><strong>会产生路由震荡，可以让每台路由器发送链路通告的时间随机化</strong></p>
<h4 id="距离向量路由算法DV"><a href="#距离向量路由算法DV" class="headerlink" title="距离向量路由算法DV"></a>距离向量路由算法DV</h4><p><strong>迭代、异步、分布式</strong></p>
<ul>
<li>分布式：每个结点要从一个或多个直接相连邻居接收某些信息，计算，将计算结果发给邻居</li>
<li>迭代：过程持续到邻居之间无更多信息交换</li>
<li>异步：不要求所有节点相互步伐一致操作</li>
</ul>
<p>DV算法<br>    Bellman-Ford方程<br>    无更新报文发送，不会出现进一步路由选择表计算，算法进入静止状态。直到一条链路费用发生改变</p>
<p>路由选择环路，无穷计数问题<br>增加毒性逆转<br>    欺骗费用无穷大。如果z通过y路由选择到目的地x，则z通告y，它（z）到x的距离是无限大。<br>    解决两个直接相连无穷计数问题，更多结点环路无法解决</p>
<h4 id="LS与DV路由选择算法的比较"><a href="#LS与DV路由选择算法的比较" class="headerlink" title="LS与DV路由选择算法的比较"></a>LS与DV路由选择算法的比较</h4><ul>
<li><strong>报文复杂性</strong><br>  显然LS复杂得多，每条链路费用改变都要通知所有结点</li>
<li><strong>收敛速度</strong><br>  DV算法收敛较慢，且会遇到路由选择环路和无穷计数问题</li>
<li><strong>健壮性</strong><br>  路由器发生故障，LS结点仅计算自己的转发表，提供了一定健壮性<br>  DV算法一个 不正确的结点会扩散到整个网络</li>
</ul>
<h4 id="层次路由选择"><a href="#层次路由选择" class="headerlink" title="层次路由选择"></a>层次路由选择</h4><p>当路由器数目变得很大，算法开销高的不可实现如LS更新链路费用<br>管理自治。一个组织应该当按自己愿望运行管理其网络<br>解决方法：将路由器组织进自治系统AS<br>每个AS由一组处在相同管理控制下的路由器组成（如相同的ISP运营）<br>相同AS中路由器全部运行同样的路由选择算法，叫做自治系统内部路由选择协议<br>一个AS内一台或多台路由器负责向本AS之外的目的地转发分组，这些路由器称为网关路由器当有多台网关路由器，需要用到自制系统间路由选择协议来配置转发表<br>因特网中所有AS中都运行相同的AS间路由选择协议BGP4</p>
<p>每台路由器接收来自一个AS内部路由选择协议和一个AS间路由选择协议的信息，并使用来自这两个协议的信息配置它的转发表。<br>某AS非网关路由器对转发表增加用于子网x（该AS外）的表项采取的动作：<br>从AS间协议知道经多个网关可达子网x<br>使用AS内部协议的路由选择信息，决定到每个网关的最低费用路径的费用<br>热土豆路由选择：选择具有最小的最低费用的网关<br>从转发表确定最低费用网关接口I，将（x,I）添加到转发表中<br>如果AS从一个相邻AS处知道一个目的地，该AS能向它某些其他相邻AS通告该路由选择信息<br>一个ISP可能分为多个互联的AS</p>
<h3 id="具体路由算法"><a href="#具体路由算法" class="headerlink" title="具体路由算法"></a>具体路由算法</h3><p>AS内部路由选择协议，又称内部网关协议<br>路由选择信息协议RIP，通常设置在下层ISP中<br>开放最短优先OSPF，通常设置在上层ISP中</p>
<h4 id="AS-自治系统-内部的路由选择：RIP（DV思想）"><a href="#AS-自治系统-内部的路由选择：RIP（DV思想）" class="headerlink" title="AS(自治系统)内部的路由选择：RIP（DV思想）"></a>AS(自治系统)内部的路由选择：RIP（DV思想）</h4><h4 id="AS内部的路由选择：OSPF（LS思想）"><a href="#AS内部的路由选择：OSPF（LS思想）" class="headerlink" title="AS内部的路由选择：OSPF（LS思想）"></a>AS内部的路由选择：OSPF（LS思想）</h4><h4 id="AS间的路由选择：BGP"><a href="#AS间的路由选择：BGP" class="headerlink" title="AS间的路由选择：BGP"></a>AS间的路由选择：BGP</h4><h4 id="多播"><a href="#多播" class="headerlink" title="多播"></a>多播</h4><p>rpf igmp</p>
<h3 id="第五章-链路层"><a href="#第五章-链路层" class="headerlink" title="第五章 链路层"></a>第五章 链路层</h3><h4 id="差错检测和纠正技术"><a href="#差错检测和纠正技术" class="headerlink" title="差错检测和纠正技术"></a>差错检测和纠正技术</h4><pre><code>奇偶校验（描述差错检测和纠正背后的思想）
检验和方法（应用于运输层）
循环冗余检测（应用在适配器中的链路层）
</code></pre>
<h4 id="多路访问链路协议"><a href="#多路访问链路协议" class="headerlink" title="多路访问链路协议"></a>多路访问链路协议</h4><p> 多路访问问题<br>    如何协调多个发送和接收结点对一个共享广播信道的访问<br>    所有结点都能传输帧，多个结点可能会同时传输帧，所有结点同时接到多个帧，传输的帧在所有接收方出碰撞了，发生碰撞时，所有帧丢失</p>
<ul>
<li>信道划分协议<br>  TDM FDM CDMA</li>
<li>随机接入协议<br>  ALOHA CSMA CSMA/CD</li>
<li>轮流协议<br>  轮询 令牌传递 DOCISIS</li>
</ul>
<h3 id="交换局域网"><a href="#交换局域网" class="headerlink" title="交换局域网"></a>交换局域网</h3><h4 id="ARP"><a href="#ARP" class="headerlink" title="ARP"></a>ARP</h4><p>提供ip地址 mac地址的转换<br>即插即用</p>
<h4 id="发送数据到子网外"><a href="#发送数据到子网外" class="headerlink" title="发送数据到子网外"></a>发送数据到子网外</h4><p>路由器有几个接口，就有几个IP地址、ARP模块和适配器，假设一个路由器连着两个子网A、B<br>子网A中的适配器要发往子网B中的适配器，先通过子网A的ARP把数据报发到子网A跟子网B相连的路由器（目的地址是路由器的MAC），路由器通过子网B的ARP将该数据报转发给目的适配器（目的地址是最终目的地的MAC）。</p>
<h4 id="交换机"><a href="#交换机" class="headerlink" title="交换机"></a>交换机</h4><p>假定目的地址为DD-DD-DD-DD-DD-DD的帧从交换机接口x到达，交换机用该MAC地址索引交换机表，有三种可能：</p>
<ol>
<li>表中没有该地址，交换机广播该帧</li>
<li>表中有表项将该地址与接口x联系起来，过滤掉，因为该帧从x来，DD也通过x去，说明该帧跟DD适配器在同一个局域网段，该帧已经在包含目的地的局域网网段广播过了</li>
<li>表中有表象将该地址与接口y≠x联系起来，该帧需要被转发到与接口y相连的局域网段，放到接口y前的输出缓存，完成转发功能</li>
</ol>
<h4 id="链路层交换机的性质"><a href="#链路层交换机的性质" class="headerlink" title="链路层交换机的性质"></a>链路层交换机的性质</h4><ol>
<li>消除碰撞<br> 交换机缓存帧并且不会在网段上同时传输多于一个帧，交换机提供了比广播链路局域网高的多的性能改善</li>
<li>异质的链路<br> 交换机将链路彼此隔离，因此局域网中的不同链路能够以不同速率运行，在不同媒介上运行</li>
<li>网络管理<br> 主动断开异常适配器<br> 收集带宽使用的统计数据、碰撞率和流量类型，这些信息用来调试解决问题</li>
</ol>
<h4 id="路由器和交换机对比"><a href="#路由器和交换机对比" class="headerlink" title="路由器和交换机对比"></a>路由器和交换机对比</h4><p>路由器是第三层的分组交换机，交换机是第二层的分组交换机<br><strong>交换机：</strong></p>
<ul>
<li>交换机即插即用，相对高的分钟过滤和转发速率</li>
<li>防止广播帧循环，交换网络的活跃拓扑限制为一颗生成树</li>
<li>大型交换网络要求在主机和路由器中有大的ARP表，生成大量ARP流量和处理量</li>
<li>对广播风暴不提供任何保护，使得以太网崩溃</li>
<li><em>路由器：</em>*</li>
<li>分组不会被限制到生成树上，可以使用源到目的地的最佳路径，拓扑结构更加丰富</li>
<li>对第二层的广播风暴提供了防火墙保护</li>
<li>不是即插即用，需要人为配置IP地址</li>
<li>对分组处理时间较长，因为必须处理第三层字段</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/06/%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/05/06/%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8-md/" itemprop="url">记录第一次使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-05-06T02:18:01+08:00">2021-05-06</time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>今天第一次用hexo搭建了blog</p>
<p>以后会陆续在上面更新自己学到的技术，欢迎大佬指正交流</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Nick</span>

  

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Pisces</a> v6.0.0</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>
























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.0"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
